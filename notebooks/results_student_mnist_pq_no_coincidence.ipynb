{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"results_mnist_pq_no_coincidence.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"goVqH-dieDrM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623155072439,"user_tz":-120,"elapsed":11184,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"2dd8c987-b0b4-406c-88b9-1d3738a27b58"},"source":["!wget https://www.dropbox.com/s/aabqnsc1mmh99kv/teacher0to4.pt\n","!wget https://www.dropbox.com/s/tl4jpuuzth5rpyh/teacher5to9.pt\n","!wget https://www.dropbox.com/s/h7l845py2d3t6o5/data.zip\n","!wget https://www.dropbox.com/s/fxpak3osyaj0i4r/u_methods_v2.csv\n","!unzip data.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-06-08 12:24:21--  https://www.dropbox.com/s/aabqnsc1mmh99kv/teacher0to4.pt\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.66.18, 2620:100:6020:18::a27d:4012\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.66.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/aabqnsc1mmh99kv/teacher0to4.pt [following]\n","--2021-06-08 12:24:21--  https://www.dropbox.com/s/raw/aabqnsc1mmh99kv/teacher0to4.pt\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc98009a3b1cac523280b2df725d.dl.dropboxusercontent.com/cd/0/inline/BQAJ8xHQoHPWUySy8BL8jFQar_ezaQAp12kDcU-bKZI4bHCW1L6GM3YvwKFxaWSCx_Y2fvi19K01xkRXLgCZmjM_z5uwV1Cf61iv6bo6NvaL41Seugr--9Ck-FVKybEpHuIzsLcJtXT6gAxUHwYd3VEO/file# [following]\n","--2021-06-08 12:24:21--  https://uc98009a3b1cac523280b2df725d.dl.dropboxusercontent.com/cd/0/inline/BQAJ8xHQoHPWUySy8BL8jFQar_ezaQAp12kDcU-bKZI4bHCW1L6GM3YvwKFxaWSCx_Y2fvi19K01xkRXLgCZmjM_z5uwV1Cf61iv6bo6NvaL41Seugr--9Ck-FVKybEpHuIzsLcJtXT6gAxUHwYd3VEO/file\n","Resolving uc98009a3b1cac523280b2df725d.dl.dropboxusercontent.com (uc98009a3b1cac523280b2df725d.dl.dropboxusercontent.com)... 162.125.67.15, 2620:100:6020:15::a27d:400f\n","Connecting to uc98009a3b1cac523280b2df725d.dl.dropboxusercontent.com (uc98009a3b1cac523280b2df725d.dl.dropboxusercontent.com)|162.125.67.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/BQB8ZMIM54EG70Mxq3z0U1RHmhgrRdO6BknBqNtbTjSZFbEq4OTZtf62JgaA3wEL42jQAyGGhqFzJtypn9nEq7Yl2PygGfjI3D4y7rrzGrD-6EpBQsOf4HPMIaXbl5STenURMxdBA412wy7z2jr1mO_aiWaZfcVihLaIpdMc_UJXxrcUfxbVihOuFxtF0tg3gwDzLukUj3qQBaUZhbceNbFbaXn-JyepGewaCgjomenWGGNqbZpPR6HnjQvbvv98Xf8OW2H7B0E9RnLflhXBaHKSc0NNiK17hH6P8WV9NINXSOYekiYG5brRo6s31Elvi8M0bi_Y0tkOD-PPLR-aRdkIKwS8KlAOWZYWnoYpsSuelpeLiu25ADk90CvOm5rKi5I/file [following]\n","--2021-06-08 12:24:22--  https://uc98009a3b1cac523280b2df725d.dl.dropboxusercontent.com/cd/0/inline2/BQB8ZMIM54EG70Mxq3z0U1RHmhgrRdO6BknBqNtbTjSZFbEq4OTZtf62JgaA3wEL42jQAyGGhqFzJtypn9nEq7Yl2PygGfjI3D4y7rrzGrD-6EpBQsOf4HPMIaXbl5STenURMxdBA412wy7z2jr1mO_aiWaZfcVihLaIpdMc_UJXxrcUfxbVihOuFxtF0tg3gwDzLukUj3qQBaUZhbceNbFbaXn-JyepGewaCgjomenWGGNqbZpPR6HnjQvbvv98Xf8OW2H7B0E9RnLflhXBaHKSc0NNiK17hH6P8WV9NINXSOYekiYG5brRo6s31Elvi8M0bi_Y0tkOD-PPLR-aRdkIKwS8KlAOWZYWnoYpsSuelpeLiu25ADk90CvOm5rKi5I/file\n","Reusing existing connection to uc98009a3b1cac523280b2df725d.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9560357 (9.1M) [application/octet-stream]\n","Saving to: ‘teacher0to4.pt’\n","\n","teacher0to4.pt      100%[===================>]   9.12M  18.3MB/s    in 0.5s    \n","\n","2021-06-08 12:24:22 (18.3 MB/s) - ‘teacher0to4.pt’ saved [9560357/9560357]\n","\n","--2021-06-08 12:24:23--  https://www.dropbox.com/s/tl4jpuuzth5rpyh/teacher5to9.pt\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.66.18, 2620:100:6020:18::a27d:4012\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.66.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/tl4jpuuzth5rpyh/teacher5to9.pt [following]\n","--2021-06-08 12:24:23--  https://www.dropbox.com/s/raw/tl4jpuuzth5rpyh/teacher5to9.pt\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc5e6bf33712a261204472097897.dl.dropboxusercontent.com/cd/0/inline/BQCvuDqLWm8SVy6Aqu_SUcfwpDNteQbah_F1bM3g7pBSkgwicxC5p51QPn10FD0ZF5kGKgYXJ8Lql-XOYmdDG1FAEzYM7BUFD-0im471YjZZ-2aEAF-mPH_aLaI5oEqT8sRFEkoTWnNfNZN4UHqAnnmG/file# [following]\n","--2021-06-08 12:24:23--  https://uc5e6bf33712a261204472097897.dl.dropboxusercontent.com/cd/0/inline/BQCvuDqLWm8SVy6Aqu_SUcfwpDNteQbah_F1bM3g7pBSkgwicxC5p51QPn10FD0ZF5kGKgYXJ8Lql-XOYmdDG1FAEzYM7BUFD-0im471YjZZ-2aEAF-mPH_aLaI5oEqT8sRFEkoTWnNfNZN4UHqAnnmG/file\n","Resolving uc5e6bf33712a261204472097897.dl.dropboxusercontent.com (uc5e6bf33712a261204472097897.dl.dropboxusercontent.com)... 162.125.64.15, 2620:100:6020:15::a27d:400f\n","Connecting to uc5e6bf33712a261204472097897.dl.dropboxusercontent.com (uc5e6bf33712a261204472097897.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/BQBEkNlLC-Btig4-4Jk7F4_W8oBuR7DtXDjo88qbrY0WxgDTPvx8D7uZvaBPlVeB3NbRdtqETYCur7gqWRCPP9kmHAUkEnR5iIgYP36yzaTjZLlwqpnLsiKxzNmw_X6gHvxUTJZHqIOay34o86POfJgIAAc8IfniobQSq3IRcgJc7MvAhr_abAe6d5iFo5c8gKnQlqq85OZWTfjpr88ZzYAQWtD7G-5HbQ4Vp6p2g-haUm0TaDYIjRWN9lwGGvJscku-hXyKOP30wCOCC45S58RTIew6LsKnF_TC3Q6EBf1AYArWcvC32u2BYdWDefZ1x_7idSX01mmz3s20P081aM3X685QcPEmd39zUBvu4l3CHavyl-aW6mgJiD5ej2VQaAs/file [following]\n","--2021-06-08 12:24:24--  https://uc5e6bf33712a261204472097897.dl.dropboxusercontent.com/cd/0/inline2/BQBEkNlLC-Btig4-4Jk7F4_W8oBuR7DtXDjo88qbrY0WxgDTPvx8D7uZvaBPlVeB3NbRdtqETYCur7gqWRCPP9kmHAUkEnR5iIgYP36yzaTjZLlwqpnLsiKxzNmw_X6gHvxUTJZHqIOay34o86POfJgIAAc8IfniobQSq3IRcgJc7MvAhr_abAe6d5iFo5c8gKnQlqq85OZWTfjpr88ZzYAQWtD7G-5HbQ4Vp6p2g-haUm0TaDYIjRWN9lwGGvJscku-hXyKOP30wCOCC45S58RTIew6LsKnF_TC3Q6EBf1AYArWcvC32u2BYdWDefZ1x_7idSX01mmz3s20P081aM3X685QcPEmd39zUBvu4l3CHavyl-aW6mgJiD5ej2VQaAs/file\n","Reusing existing connection to uc5e6bf33712a261204472097897.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9560357 (9.1M) [application/octet-stream]\n","Saving to: ‘teacher5to9.pt’\n","\n","teacher5to9.pt      100%[===================>]   9.12M  8.88MB/s    in 1.0s    \n","\n","2021-06-08 12:24:25 (8.88 MB/s) - ‘teacher5to9.pt’ saved [9560357/9560357]\n","\n","--2021-06-08 12:24:25--  https://www.dropbox.com/s/h7l845py2d3t6o5/data.zip\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.66.18, 2620:100:6020:18::a27d:4012\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.66.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/h7l845py2d3t6o5/data.zip [following]\n","--2021-06-08 12:24:25--  https://www.dropbox.com/s/raw/h7l845py2d3t6o5/data.zip\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc3b675c89b25afe52bc80e10811.dl.dropboxusercontent.com/cd/0/inline/BQCYtXK0YMA-EmaZ9AVcASkDr1zZ0Av4LjnnCsdCIWw5edtawM8XcSACU-TKcg385aAstCh5F77bT1YCjFZAeJcOs29vYFFU5BZ35RlAkKM9b91o-1cWJZ2YAmx4zU5aRac-9SKuZv8t-2yZtjOJJK1j/file# [following]\n","--2021-06-08 12:24:26--  https://uc3b675c89b25afe52bc80e10811.dl.dropboxusercontent.com/cd/0/inline/BQCYtXK0YMA-EmaZ9AVcASkDr1zZ0Av4LjnnCsdCIWw5edtawM8XcSACU-TKcg385aAstCh5F77bT1YCjFZAeJcOs29vYFFU5BZ35RlAkKM9b91o-1cWJZ2YAmx4zU5aRac-9SKuZv8t-2yZtjOJJK1j/file\n","Resolving uc3b675c89b25afe52bc80e10811.dl.dropboxusercontent.com (uc3b675c89b25afe52bc80e10811.dl.dropboxusercontent.com)... 162.125.66.15, 2620:100:6017:15::a27d:20f\n","Connecting to uc3b675c89b25afe52bc80e10811.dl.dropboxusercontent.com (uc3b675c89b25afe52bc80e10811.dl.dropboxusercontent.com)|162.125.66.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/BQCAhEaYNIXfu32b5NdPJjCdsMGGMprhChd0FQF5HJPU1jCEtrHrjZlsMJpif8KBLHf-zpCIgeUb9qUYZkPTFpScty_CQ-Z0SkPGGYTWuy3gsX7jcd9STbqUAhLxHZJY9j0nOsMUiSHnme_fsghB2Het0GWAbxCOPbyONy2LQZCLxDYoDl8jLi7WeXtKGoYw1_VPuuNf4edT63AyRis5Km7zoCCl_QdGreth-__4YqVATPFyOhbLnh54fBTUHQ7rYvH7ApozSi6bYEIvhDkFOgn-CuaxMF0iVZisMWUjf7oKVjXjbeUXH3oMZFai6j2lYESyx6p5wCvmmJAjngeJkyXn6RpR0fhEzriJx5bhCnEkIgobI6bYXP-2Xw4ozBkQ644/file [following]\n","--2021-06-08 12:24:26--  https://uc3b675c89b25afe52bc80e10811.dl.dropboxusercontent.com/cd/0/inline2/BQCAhEaYNIXfu32b5NdPJjCdsMGGMprhChd0FQF5HJPU1jCEtrHrjZlsMJpif8KBLHf-zpCIgeUb9qUYZkPTFpScty_CQ-Z0SkPGGYTWuy3gsX7jcd9STbqUAhLxHZJY9j0nOsMUiSHnme_fsghB2Het0GWAbxCOPbyONy2LQZCLxDYoDl8jLi7WeXtKGoYw1_VPuuNf4edT63AyRis5Km7zoCCl_QdGreth-__4YqVATPFyOhbLnh54fBTUHQ7rYvH7ApozSi6bYEIvhDkFOgn-CuaxMF0iVZisMWUjf7oKVjXjbeUXH3oMZFai6j2lYESyx6p5wCvmmJAjngeJkyXn6RpR0fhEzriJx5bhCnEkIgobI6bYXP-2Xw4ozBkQ644/file\n","Reusing existing connection to uc3b675c89b25afe52bc80e10811.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 34602005 (33M) [application/zip]\n","Saving to: ‘data.zip’\n","\n","data.zip            100%[===================>]  33.00M  18.4MB/s    in 1.8s    \n","\n","2021-06-08 12:24:28 (18.4 MB/s) - ‘data.zip’ saved [34602005/34602005]\n","\n","--2021-06-08 12:24:28--  https://www.dropbox.com/s/fxpak3osyaj0i4r/u_methods_v2.csv\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.64.18, 2620:100:6020:18::a27d:4012\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.64.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/fxpak3osyaj0i4r/u_methods_v2.csv [following]\n","--2021-06-08 12:24:29--  https://www.dropbox.com/s/raw/fxpak3osyaj0i4r/u_methods_v2.csv\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc6da402ffab27e1cefee49e815f.dl.dropboxusercontent.com/cd/0/inline/BQAcfR72gpv88QkgyEqqXYKFc-ZhCSvKWS826OJKvveSOF57sHgqMYO9AhR4L9GMef9rh54egSwZXF9cbj7tkW0_jFb-entStpuVgvTkAX--t8y1yMlQxP7ykImtYdOcFHlTqSjDHFDQqSltMeX89hn6/file# [following]\n","--2021-06-08 12:24:29--  https://uc6da402ffab27e1cefee49e815f.dl.dropboxusercontent.com/cd/0/inline/BQAcfR72gpv88QkgyEqqXYKFc-ZhCSvKWS826OJKvveSOF57sHgqMYO9AhR4L9GMef9rh54egSwZXF9cbj7tkW0_jFb-entStpuVgvTkAX--t8y1yMlQxP7ykImtYdOcFHlTqSjDHFDQqSltMeX89hn6/file\n","Resolving uc6da402ffab27e1cefee49e815f.dl.dropboxusercontent.com (uc6da402ffab27e1cefee49e815f.dl.dropboxusercontent.com)... 162.125.66.15, 2620:100:6020:15::a27d:400f\n","Connecting to uc6da402ffab27e1cefee49e815f.dl.dropboxusercontent.com (uc6da402ffab27e1cefee49e815f.dl.dropboxusercontent.com)|162.125.66.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19803827 (19M) [text/plain]\n","Saving to: ‘u_methods_v2.csv’\n","\n","u_methods_v2.csv    100%[===================>]  18.89M  17.0MB/s    in 1.1s    \n","\n","2021-06-08 12:24:30 (17.0 MB/s) - ‘u_methods_v2.csv’ saved [19803827/19803827]\n","\n","Archive:  data.zip\n","   creating: data/\n","   creating: data/MNIST/\n","   creating: data/MNIST/raw/\n","  inflating: data/MNIST/raw/train-images-idx3-ubyte.gz  \n","  inflating: data/MNIST/raw/train-images-idx3-ubyte  \n","  inflating: data/MNIST/raw/train-labels-idx1-ubyte.gz  \n","  inflating: data/MNIST/raw/train-labels-idx1-ubyte  \n","  inflating: data/MNIST/raw/t10k-images-idx3-ubyte.gz  \n","  inflating: data/MNIST/raw/t10k-images-idx3-ubyte  \n","  inflating: data/MNIST/raw/t10k-labels-idx1-ubyte.gz  \n","  inflating: data/MNIST/raw/t10k-labels-idx1-ubyte  \n","   creating: data/MNIST/processed/\n","  inflating: data/MNIST/processed/training.pt  \n","  inflating: data/MNIST/processed/test.pt  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XmqRVp61lCFu"},"source":["# LOADING MODEL AND MNIST CLASSES"]},{"cell_type":"code","metadata":{"id":"jOk72lj4eXJD"},"source":["import os\n","import time\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import torch.nn as nn\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# Import torchvision functions/classes for MNIST import and data loaders\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","class Model(nn.Module):\n","\n","    def __init__(self, n_classes, hidden_size=1200, dropout=0.0, hidden_dropout=0.0):\n","        super(Model, self).__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        self.hidden1 = nn.Linear(784, hidden_size, bias=True)\n","        self.hidden1_dropout = nn.Dropout(hidden_dropout)\n","        self.hidden2 = nn.Linear(hidden_size, hidden_size, bias=True)\n","        self.hidden2_dropout = nn.Dropout(hidden_dropout)\n","        self.hidden3 = nn.Linear(hidden_size, n_classes, bias=True)\n","\n","    def forward(self, x):\n","\n","        x = self.dropout(x)\n","        x = F.relu(self.hidden1(x))\n","        x = self.hidden1_dropout(x)\n","        x = F.relu(self.hidden2(x))\n","        x = self.hidden2_dropout(x)\n","        x = self.hidden3(x)\n","        return x\n","\n","\n","\n","class MnistDataset(Dataset):\n","    def __init__(self, data, target, transformation=None):\n","        self.images = data\n","        self.targets = target\n","        self.transformation = transforms.Compose([\n","              transforms.RandomAffine(0, (1/14, 1/14)),\n","              transforms.Normalize((0.5,), (0.5,))\n","            ])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","\n","    def __getitem__(self, idx):\n","        return self.images[idx], self.targets[idx]\n","\n","\n","class MnistQs():\n","      def __init__(self):\n","          self.df = pd.read_pickle(\"u_methods_v2.csv\")\n","          self.u_CE = self.df[\"u_CE\"]\n","          self.u_MFPS = self.df[\"u_MFPS\"]\n","          self.u_MFLS = self.df[\"u_MFLS\"]\n","\n","      def __len__(self):\n","          return self.df.shape[0]\n","\n","      def __getitem__(self, idx):\n","          return self.u_CE.iloc[idx], self.u_MFPS.iloc[idx], self.u_MFLS.iloc[idx]\n","\n","      def get_u_CE(self):\n","          self.u_CE = torch.zeros(60000, 10)\n","\n","          for idx, u in enumerate(self.df.u_CE):\n","              self.u_CE[idx, :] = torch.tensor(u)\n","\n","          return self.u_CE\n","\n","      def get_u_MFPS(self):\n","          self.u_MFPS = torch.zeros(60000, 10)\n","\n","          for idx, u in enumerate(self.df.u_MFPS):\n","              self.u_MFPS[idx, :] = torch.tensor(u)\n","          \n","          return self.u_MFPS\n","\n","      def get_u_MFLS(self):\n","          self.u_MFLS = torch.zeros(60000, 10)\n","\n","          for idx, u in enumerate(self.df.u_MFLS):\n","              self.u_MFLS[idx, :] = torch.tensor(u)\n","          \n","          return self.u_MFLS\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNMq0X6dlOM8"},"source":["# LOAD THE DATASET AND THE TEACHER FILES"]},{"cell_type":"code","metadata":{"id":"vmPFPSOF5XHh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623155116964,"user_tz":-120,"elapsed":9799,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"dce5b3de-4159-440c-ef33-3e23bc529176"},"source":["teacher1 = torch.load(\"teacher0to4.pt\")\n","teacher1.to(\"cuda\")\n","teacher2 = torch.load(\"teacher5to9.pt\")\n","teacher2.to(\"cuda\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (hidden1): Linear(in_features=784, out_features=1200, bias=True)\n","  (hidden1_dropout): Dropout(p=0.5, inplace=False)\n","  (hidden2): Linear(in_features=1200, out_features=1200, bias=True)\n","  (hidden2_dropout): Dropout(p=0.5, inplace=False)\n","  (hidden3): Linear(in_features=1200, out_features=5, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"-Av2AqFeYyzG"},"source":["# IMPLEMENTING THE STUDENT"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kmnNcU1xXGl","executionInfo":{"status":"ok","timestamp":1620239036874,"user_tz":-120,"elapsed":1022,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"6fc381c3-2ff3-4585-87dc-2fda58010c08"},"source":["60000/125"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["480.0"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"sDBt_SqRbtg4"},"source":["images, targets = torch.load(\"/content/data/MNIST/processed/training.pt\")\n","trainset = MnistDataset(images, targets)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=125, shuffle=False, num_workers=2)\n","mnistq = MnistQs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11_YXrZiubul"},"source":["student_CE = Model(n_classes=10, hidden_size=500, dropout=0.1, hidden_dropout=0.1)\n","student_CE.to(\"cuda\")\n","\n","criterion = nn.KLDivLoss()\n","m = nn.Softmax(dim=0)\n","learning_rate = 0.001\n","epochs = 50\n","\n","# Set up loss function and optimizer\n","optimizer = optim.SGD(student_CE.parameters(), lr=learning_rate, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r-gy17UcAKiN"},"source":["# Training student with method 1"]},{"cell_type":"code","metadata":{"id":"yIpajMSFYxKD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623155280310,"user_tz":-120,"elapsed":151611,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"91378207-8f8e-437f-c038-de044bd6d446"},"source":["# Run over 1000 epochs (1 epoch = visited all items in dataset)\n","for epoch in range(epochs):\n","    running_loss = 0.0\n","    total = 0\n","\n","    for image, qs in zip(trainloader, np.array_split(mnistq.get_u_CE(), 480)):\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(student_CE.parameters(), lr= learning_rate, momentum=0.9)\n","        \n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, targets = image\n","        inputs = torch.flatten(inputs, start_dim=1).to(\"cuda\")\n","        qs = qs.to(\"cuda\")\n","        # target = labels.to(\"cuda\").long()\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Set temperature and the weights for losses linear combination\n","        w = 0.7\n","        T = 3\n","\n","        # Student forward + backward + optimize\n","        logits_student = student_CE(inputs.float())\n","        # loss = torch.cdist(m(qs), m(logits_student), p=2)\n","        loss = criterion(F.log_softmax(qs/T, dim=1), F.softmax(logits_student/T, dim=1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(image)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2611: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["[1] loss: 0.029\n","[2] loss: 0.014\n","[3] loss: 0.011\n","[4] loss: 0.010\n","[5] loss: 0.009\n","[6] loss: 0.008\n","[7] loss: 0.008\n","[8] loss: 0.008\n","[9] loss: 0.007\n","[10] loss: 0.007\n","[11] loss: 0.007\n","[12] loss: 0.007\n","[13] loss: 0.007\n","[14] loss: 0.007\n","[15] loss: 0.007\n","[16] loss: 0.007\n","[17] loss: 0.006\n","[18] loss: 0.006\n","[19] loss: 0.006\n","[20] loss: 0.006\n","[21] loss: 0.006\n","[22] loss: 0.006\n","[23] loss: 0.006\n","[24] loss: 0.006\n","[25] loss: 0.006\n","[26] loss: 0.006\n","[27] loss: 0.006\n","[28] loss: 0.006\n","[29] loss: 0.006\n","[30] loss: 0.006\n","[31] loss: 0.006\n","[32] loss: 0.006\n","[33] loss: 0.006\n","[34] loss: 0.006\n","[35] loss: 0.006\n","[36] loss: 0.006\n","[37] loss: 0.006\n","[38] loss: 0.006\n","[39] loss: 0.005\n","[40] loss: 0.005\n","[41] loss: 0.005\n","[42] loss: 0.005\n","[43] loss: 0.005\n","[44] loss: 0.005\n","[45] loss: 0.005\n","[46] loss: 0.005\n","[47] loss: 0.005\n","[48] loss: 0.005\n","[49] loss: 0.005\n","[50] loss: 0.005\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vZ8QrWTAepS6"},"source":["# Testing student with method 1"]},{"cell_type":"code","metadata":{"id":"GmlcMHLDd7C4"},"source":["images_test, targets_test = torch.load(\"/content/data/MNIST/processed/test.pt\")\n","testset = MnistDataset(images_test, targets_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RydXmyvIcDJK","executionInfo":{"status":"ok","timestamp":1623155696945,"user_tz":-120,"elapsed":1048,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"6d435b63-2c71-48b5-d187-29acd4a77663"},"source":["# Define support function used to convert label to one-hot encoded tensor\n","def convert_labels(labels):\n","    target = torch.zeros([len(labels), 10], dtype=torch.float32)\n","    for i, l in enumerate(labels):\n","      target[i][l] = 1.0\n","    return target\n","\n","# Run model on test set and determine accuracy\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(\"cuda\")\n","        target = convert_labels(labels).to(\"cuda\")\n","        outputs = student_CE(inputs.float())\n","        _, predicted = torch.max(outputs.data, 1)\n","        _, target = torch.max(target.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","        # for i, val in enumerate(predicted):\n","        #   wrong[target[i]][val] += 1\n","\n","# Output model accuracy to user\n","print('Accuracy of the network on test images: %d %% (%d wrong out of %d)' % (\n","    100 * correct / total, total - correct, total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(8, device='cuda:0')\n","Accuracy of the network on test images: 74 % (2552 wrong out of 10000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3KQxT3bPn3xg","executionInfo":{"status":"ok","timestamp":1623157494222,"user_tz":-120,"elapsed":1446,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"1b34571a-b021-450c-83d0-b727901df7f3"},"source":["classes = np.arange(0, 10)\n","\n","# prepare to count predictions for each class\n","correct_pred = {classname: 0 for classname in classes}\n","total_pred = {classname: 0 for classname in classes}\n","\n","# again no gradients needed\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(\"cuda\")\n","        target = convert_labels(labels).to(\"cuda\")\n","        outputs = student_CE(inputs.float())\n","        _, predictions = torch.max(outputs, 1)\n","        _, target = torch.max(target.data, 1)\n","        # collect the correct predictions for each class\n","        for label, prediction in zip(target, predictions):\n","            if label == prediction:\n","                correct_pred[classes[label]] += 1\n","            total_pred[classes[label]] += 1\n","\n","print(correct_pred)\n","print(total_pred)\n","\n","\n","# print accuracy for each class\n","for classname, correct_count in correct_pred.items():\n","    accuracy = 100 * float(correct_count) / total_pred[classname]\n","    print(f\"Accuracy for {str(classname)} is: {round(accuracy, 4)} %\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{0: 869, 1: 915, 2: 687, 3: 848, 4: 741, 5: 518, 6: 771, 7: 836, 8: 780, 9: 614}\n","{0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n","Accuracy for 0 is: 88.6735 %\n","Accuracy for 1 is: 80.6167 %\n","Accuracy for 2 is: 66.5698 %\n","Accuracy for 3 is: 83.9604 %\n","Accuracy for 4 is: 75.4582 %\n","Accuracy for 5 is: 58.0717 %\n","Accuracy for 6 is: 80.4802 %\n","Accuracy for 7 is: 81.323 %\n","Accuracy for 8 is: 80.0821 %\n","Accuracy for 9 is: 60.8523 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u8ZTn_hKAQCS"},"source":["# Training student with method 2 (MFPS)"]},{"cell_type":"code","metadata":{"id":"QCNZY5HeAmlo"},"source":["student_MFPS = Model(n_classes=10, hidden_size=500, dropout=0.1, hidden_dropout=0.1)\n","student_MFPS.to(\"cuda\")\n","\n","# bce_with_logits = torch.nn.BCEWithLogitsLoss()\n","learning_rate = 0.001\n","epochs = 20\n","m = nn.Softmax(dim=1)\n","\n","# Set up loss function and optimizer\n","optimizer = optim.SGD(student_MFPS.parameters(), lr=0.001, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y82aZoYipsyF"},"source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    total = 0\n","\n","    for image, qs in zip(trainloader, np.array_split(mnistq.get_u_MFPS(), 480)):\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(student_MFPS.parameters(), lr= learning_rate, momentum=0.9)\n","        \n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, targets = image\n","        inputs = torch.flatten(inputs, start_dim=1).to(\"cuda\")\n","        \n","        qs = qs.to(\"cuda\")\n","        # target = labels.to(\"cuda\").long()\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Set temperature and the weights for losses linear combination\n","        w = 0.7\n","        T = 2\n","\n","        # Student forward + backward + optimize\n","        logits_student = student_MFPS(inputs.float())\n","        # loss = criterion(F.log_softmax(qs/T, dim=1), F.softmax(logits_student/T, dim=1))\n","        loss = criterion(qs, m(logits_student/T))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(image)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yZFYVCtNzZLy"},"source":["# Testing student with method 2 (MFPS)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRviYWpAzYwA","executionInfo":{"status":"ok","timestamp":1620239738035,"user_tz":-120,"elapsed":933,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"e460be55-3ad4-42bb-9c95-30d132bed26b"},"source":["# Define support function used to convert label to one-hot encoded tensor\n","def convert_labels(labels):\n","    target = torch.zeros([len(labels), 10], dtype=torch.float32)\n","    for i, l in enumerate(labels):\n","      target[i][l] = 1.0\n","    return target\n","\n","# Run model on test set and determine accuracy\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(\"cuda\")\n","        target = convert_labels(labels).to(\"cuda\")\n","        outputs = student_MFPS(inputs.float())\n","        _, predicted = torch.max(outputs.data, 1)\n","        _, target = torch.max(target.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","        # for i, val in enumerate(predicted):\n","        #   wrong[target[i]][val] += 1\n","\n","# Output model accuracy to user\n","print('Accuracy of the network on test images: %d %% (%d wrong out of %d)' % (\n","    100 * correct / total, total - correct, total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the network on test images: 33 % (6675 wrong out of 10000)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xokyrdEfAVfZ"},"source":["# Training student with method 2 (MFLS)"]},{"cell_type":"code","metadata":{"id":"yuQUz13nBIP1"},"source":["student_MFLS = Model(n_classes=10, hidden_size=500, dropout=0.1, hidden_dropout=0.1)\n","student_MFLS.to(\"cuda\")\n","\n","criterion = nn.KLDivLoss()\n","m = nn.Softmax(dim=0)\n","learning_rate = 0.001\n","epochs = 100\n","\n","# Set up loss function and optimizer\n","optimizer = optim.SGD(student_MFLS.parameters(), lr=0.001, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EcbnEYKnOcg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623158312055,"user_tz":-120,"elapsed":295206,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"e08fa8c2-ecf9-4eb7-eeaa-817ba6b28b6e"},"source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    total = 0\n","\n","    for image, qs in zip(trainloader, np.array_split(mnistq.get_u_MFLS(), 480)):\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(student_MFLS.parameters(), lr= learning_rate, momentum=0.9)\n","        \n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, targets = image\n","        inputs = torch.flatten(inputs, start_dim=1).to(\"cuda\")\n","        qs = qs.to(\"cuda\")\n","        # target = labels.to(\"cuda\").long()\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Set temperature and the weights for losses linear combination\n","        w = 0.7\n","        T = 15\n","\n","        # Student forward + backward + optimize\n","        logits_student = student_MFLS(inputs.float())\n","        loss = criterion(F.log_softmax(qs/T, dim=1), F.softmax(logits_student/T, dim=1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(image)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2611: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["[1] loss: 0.039\n","[2] loss: 0.025\n","[3] loss: 0.023\n","[4] loss: 0.022\n","[5] loss: 0.021\n","[6] loss: 0.020\n","[7] loss: 0.020\n","[8] loss: 0.019\n","[9] loss: 0.019\n","[10] loss: 0.018\n","[11] loss: 0.018\n","[12] loss: 0.018\n","[13] loss: 0.018\n","[14] loss: 0.017\n","[15] loss: 0.017\n","[16] loss: 0.017\n","[17] loss: 0.017\n","[18] loss: 0.017\n","[19] loss: 0.016\n","[20] loss: 0.016\n","[21] loss: 0.016\n","[22] loss: 0.016\n","[23] loss: 0.016\n","[24] loss: 0.016\n","[25] loss: 0.016\n","[26] loss: 0.016\n","[27] loss: 0.016\n","[28] loss: 0.016\n","[29] loss: 0.015\n","[30] loss: 0.015\n","[31] loss: 0.015\n","[32] loss: 0.015\n","[33] loss: 0.015\n","[34] loss: 0.015\n","[35] loss: 0.015\n","[36] loss: 0.015\n","[37] loss: 0.015\n","[38] loss: 0.015\n","[39] loss: 0.015\n","[40] loss: 0.015\n","[41] loss: 0.015\n","[42] loss: 0.015\n","[43] loss: 0.015\n","[44] loss: 0.015\n","[45] loss: 0.015\n","[46] loss: 0.015\n","[47] loss: 0.014\n","[48] loss: 0.014\n","[49] loss: 0.014\n","[50] loss: 0.014\n","[51] loss: 0.014\n","[52] loss: 0.014\n","[53] loss: 0.014\n","[54] loss: 0.014\n","[55] loss: 0.014\n","[56] loss: 0.014\n","[57] loss: 0.014\n","[58] loss: 0.014\n","[59] loss: 0.014\n","[60] loss: 0.014\n","[61] loss: 0.014\n","[62] loss: 0.014\n","[63] loss: 0.014\n","[64] loss: 0.014\n","[65] loss: 0.014\n","[66] loss: 0.014\n","[67] loss: 0.014\n","[68] loss: 0.014\n","[69] loss: 0.014\n","[70] loss: 0.014\n","[71] loss: 0.014\n","[72] loss: 0.014\n","[73] loss: 0.014\n","[74] loss: 0.014\n","[75] loss: 0.014\n","[76] loss: 0.014\n","[77] loss: 0.014\n","[78] loss: 0.014\n","[79] loss: 0.014\n","[80] loss: 0.014\n","[81] loss: 0.014\n","[82] loss: 0.014\n","[83] loss: 0.014\n","[84] loss: 0.014\n","[85] loss: 0.014\n","[86] loss: 0.014\n","[87] loss: 0.013\n","[88] loss: 0.014\n","[89] loss: 0.014\n","[90] loss: 0.013\n","[91] loss: 0.013\n","[92] loss: 0.013\n","[93] loss: 0.013\n","[94] loss: 0.013\n","[95] loss: 0.013\n","[96] loss: 0.013\n","[97] loss: 0.013\n","[98] loss: 0.013\n","[99] loss: 0.013\n","[100] loss: 0.013\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hXu1ZRhYBTs7"},"source":["# Testing student with method 2 MFLS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mE-ClvWVBCKB","executionInfo":{"status":"ok","timestamp":1623158380197,"user_tz":-120,"elapsed":891,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"53c287a3-9273-4627-a1b5-9e2f0b5efe0d"},"source":["# Define support function used to convert label to one-hot encoded tensor\n","def convert_labels(labels):\n","    target = torch.zeros([len(labels), 10], dtype=torch.float32)\n","    for i, l in enumerate(labels):\n","      target[i][l] = 1.0\n","    return target\n","\n","# Run model on test set and determine accuracy\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(\"cuda\")\n","        target = convert_labels(labels).to(\"cuda\")\n","        outputs = student_MFLS(inputs.float())\n","        _, predicted = torch.max(outputs.data, 1)\n","        _, target = torch.max(target.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","        # for i, val in enumerate(predicted):\n","        #   wrong[target[i]][val] += 1\n","\n","# Output model accuracy to user\n","print('Accuracy of the network on test images: %d %% (%d wrong out of %d)' % (\n","    100 * correct / total, total - correct, total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the network on test images: 82 % (1792 wrong out of 10000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YvS8uG3uqNh","executionInfo":{"status":"ok","timestamp":1623158388436,"user_tz":-120,"elapsed":1183,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"5ff4dac4-093f-4df3-e501-ad88cb94d017"},"source":["classes = np.arange(0, 10)\n","\n","# prepare to count predictions for each class\n","correct_pred = {classname: 0 for classname in classes}\n","total_pred = {classname: 0 for classname in classes}\n","\n","# again no gradients needed\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(\"cuda\")\n","        target = convert_labels(labels).to(\"cuda\")\n","        outputs = student_MFLS(inputs.float())\n","        _, predictions = torch.max(outputs, 1)\n","        _, target = torch.max(target.data, 1)\n","        # collect the correct predictions for each class\n","        for label, prediction in zip(target, predictions):\n","            if label == prediction:\n","                correct_pred[classes[label]] += 1\n","            total_pred[classes[label]] += 1\n","\n","print(correct_pred)\n","print(total_pred)\n","\n","\n","# print accuracy for each class\n","for classname, correct_count in correct_pred.items():\n","    accuracy = 100 * float(correct_count) / total_pred[classname]\n","    print(f\"Accuracy for {str(classname)} is: {round(accuracy, 4)} %\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{0: 967, 1: 1100, 2: 781, 3: 833, 4: 460, 5: 493, 6: 705, 7: 969, 8: 916, 9: 968}\n","{0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n","Accuracy for 0 is: 98.6735 %\n","Accuracy for 1 is: 96.9163 %\n","Accuracy for 2 is: 75.6783 %\n","Accuracy for 3 is: 82.4752 %\n","Accuracy for 4 is: 46.8432 %\n","Accuracy for 5 is: 55.2691 %\n","Accuracy for 6 is: 73.5908 %\n","Accuracy for 7 is: 94.2607 %\n","Accuracy for 8 is: 94.0452 %\n","Accuracy for 9 is: 95.9366 %\n"],"name":"stdout"}]}]}