{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"results_mnist_pq_CNN.ipynb","provenance":[],"collapsed_sections":["Veyl-ielnc8k"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"goVqH-dieDrM"},"source":["!wget https://www.dropbox.com/s/2nyrobwxi99suda/u_methods_CNN.csv\n","!wget https://www.dropbox.com/s/06s5ivbtnz64ii7/teacher0to4_CNN.pt\n","!wget https://www.dropbox.com/s/aq196om1h3lvkjs/teacher5to9_CNN.pt\n","!wget https://www.dropbox.com/s/h7l845py2d3t6o5/data.zip\n","!unzip data.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XmqRVp61lCFu"},"source":["# LOADING MODEL AND MNIST CLASSES"]},{"cell_type":"code","metadata":{"id":"jOk72lj4eXJD","executionInfo":{"status":"ok","timestamp":1622668713467,"user_tz":-120,"elapsed":418,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}}},"source":["from __future__ import print_function\n","import numpy as np\n","import pandas as pd\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset\n","from torch.optim.lr_scheduler import StepLR\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n","        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n","        self.fc1 = nn.Linear(3*3*64, 256)\n","        self.fc2 = nn.Linear(256, 5)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(F.max_pool2d(self.conv3(x),2))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = x.view(-1,3*3*64 )\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","\n","\n","class student(nn.Module):\n","    def __init__(self):\n","        super(student, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n","        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n","        self.fc1 = nn.Linear(3*3*64, 256)\n","        self.fc2 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(F.max_pool2d(self.conv3(x),2))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = x.view(-1,3*3*64)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","\n","class MnistDataset(Dataset):\n","    def __init__(self, data, target, transformation=None):\n","        self.images = data\n","        self.targets = target\n","        self.transformation = transforms.Compose(\n","              [transforms.ToTensor(), \n","               transforms.Normalize((0.5, 0.5, 0.5), \n","                                    (0.5, 0.5, 0.5))])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","\n","    def __getitem__(self, idx):\n","        return self.images[idx], self.targets[idx]\n","\n","\n","class MnistQs():\n","      def __init__(self):\n","          self.df = pd.read_pickle(\"u_methods_CNN.csv\")\n","          self.u_CE = self.df[\"u_CE\"]\n","          self.u_MFPS = self.df[\"u_MFPS\"]\n","          self.u_MFLS = self.df[\"u_MFLS\"]\n","\n","      def __len__(self):\n","          return self.df.shape[0]\n","\n","      def __getitem__(self, idx):\n","          return self.u_CE.iloc[idx], self.u_MFPS.iloc[idx], self.u_MFLS.iloc[idx]\n","\n","      def get_u_CE(self):\n","          self.u_CE = torch.zeros(60000, 10)\n","\n","          for idx, u in enumerate(self.df.u_CE):\n","              self.u_CE[idx, :] = torch.tensor(u)\n","\n","          return self.u_CE\n","\n","      def get_u_MFPS(self):\n","          self.u_MFPS = torch.zeros(60000, 10)\n","\n","          for idx, u in enumerate(self.df.u_MFPS):\n","              self.u_MFPS[idx, :] = torch.tensor(u)\n","          \n","          return self.u_MFPS\n","\n","      def get_u_MFLS(self):\n","          self.u_MFLS = torch.zeros(60000, 10)\n","\n","          for idx, u in enumerate(self.df.u_MFLS):\n","              self.u_MFLS[idx, :] = torch.tensor(u)\n","          \n","          return self.u_MFLS"],"execution_count":85,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNMq0X6dlOM8"},"source":["# LOAD THE DATASET AND THE TEACHER FILES"]},{"cell_type":"code","metadata":{"id":"vmPFPSOF5XHh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622668718343,"user_tz":-120,"elapsed":343,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"4e77cb3c-0484-43f3-ec6d-9a77e5a9edd1"},"source":["teacher1 = torch.load(\"teacher0to4_CNN.pt\")\n","teacher1.to(\"cuda\")\n","teacher2 = torch.load(\"teacher5to9_CNN.pt\")\n","teacher2.to(\"cuda\")"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=576, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=5, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"AHXo-3pkdJuN","executionInfo":{"status":"ok","timestamp":1622668719553,"user_tz":-120,"elapsed":3,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}}},"source":["images_train, targets_train = torch.load(\"/content/data/MNIST/processed/training.pt\")\n","trainset = MnistDataset(images_train, targets_train)\n","trainset.images = trainset.images.view(-1, 1,28,28).float()\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=125, shuffle=False, num_workers=2)"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"id":"GmlcMHLDd7C4","executionInfo":{"status":"ok","timestamp":1622669314451,"user_tz":-120,"elapsed":314,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}}},"source":["images_test, targets_test = torch.load(\"/content/data/MNIST/processed/test.pt\")\n","testset = MnistDataset(images_test, targets_test)\n","testset.images = testset.images.view(-1, 1,28,28).float()\n","testloader = torch.utils.data.DataLoader(testset, batch_size=125, shuffle=True, num_workers=2)"],"execution_count":97,"outputs":[]},{"cell_type":"code","metadata":{"id":"GyL0H_MVdmSj","executionInfo":{"status":"ok","timestamp":1622668723500,"user_tz":-120,"elapsed":416,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}}},"source":["mnistq = MnistQs()"],"execution_count":89,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_BXoAglnlnUM"},"source":["# FIRST METHOD (CROSS ENTROPY)"]},{"cell_type":"markdown","metadata":{"id":"PTcviPQBaijV"},"source":["# Training student with method 1"]},{"cell_type":"code","metadata":{"id":"X6bZzytQalyp","executionInfo":{"status":"ok","timestamp":1622668887747,"user_tz":-120,"elapsed":420,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}}},"source":["device = \"cuda\"\n","student_CE = student()\n","student_CE.to(\"cuda\")\n","\n","# bce_with_logits = torch.nn.BCEWithLogitsLoss()\n","learning_rate = 0.001\n","epochs = 100\n","m = nn.Softmax(dim=1)\n","criterion = nn.KLDivLoss()\n","\n","# Set up loss function and optimizer\n","optimizer = optim.SGD(student_CE.parameters(), lr=learning_rate, momentum=0.9)"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPRUHvpIampA","executionInfo":{"status":"ok","timestamp":1622669250475,"user_tz":-120,"elapsed":359657,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"51565ca7-22e2-4ab6-c362-159c3e6887e8"},"source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    total = 0\n","\n","    for image, qs in zip(trainloader, np.array_split(mnistq.get_u_CE(), 480)):\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(student_CE.parameters(), lr= learning_rate, momentum=0.9)\n","        \n","        # get the inputs\n","        inputs, targets = image\n","        inputs = inputs.to(\"cuda\")\n","        qs = qs.to(\"cuda\")\n","        \n","        # target = labels.to(\"cuda\").long()\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Set temperature and the weights for losses linear combination\n","        w = 0.7\n","        T = 3\n","\n","        # Student forward + backward + optimize\n","        logits_student = student_CE(inputs.float())\n","        loss = criterion(F.log_softmax(qs/T, dim=1), F.softmax(logits_student/T, dim=1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(image)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":96,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2611: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["[1] loss: 0.021\n","[2] loss: 0.016\n","[3] loss: 0.016\n","[4] loss: 0.016\n","[5] loss: 0.015\n","[6] loss: 0.015\n","[7] loss: 0.014\n","[8] loss: 0.014\n","[9] loss: 0.013\n","[10] loss: 0.013\n","[11] loss: 0.012\n","[12] loss: 0.012\n","[13] loss: 0.012\n","[14] loss: 0.011\n","[15] loss: 0.011\n","[16] loss: 0.011\n","[17] loss: 0.011\n","[18] loss: 0.010\n","[19] loss: 0.010\n","[20] loss: 0.010\n","[21] loss: 0.010\n","[22] loss: 0.010\n","[23] loss: 0.009\n","[24] loss: 0.009\n","[25] loss: 0.009\n","[26] loss: 0.009\n","[27] loss: 0.009\n","[28] loss: 0.009\n","[29] loss: 0.009\n","[30] loss: 0.009\n","[31] loss: 0.009\n","[32] loss: 0.009\n","[33] loss: 0.008\n","[34] loss: 0.008\n","[35] loss: 0.008\n","[36] loss: 0.008\n","[37] loss: 0.008\n","[38] loss: 0.008\n","[39] loss: 0.008\n","[40] loss: 0.008\n","[41] loss: 0.008\n","[42] loss: 0.008\n","[43] loss: 0.008\n","[44] loss: 0.008\n","[45] loss: 0.008\n","[46] loss: 0.008\n","[47] loss: 0.008\n","[48] loss: 0.008\n","[49] loss: 0.008\n","[50] loss: 0.008\n","[51] loss: 0.007\n","[52] loss: 0.007\n","[53] loss: 0.007\n","[54] loss: 0.007\n","[55] loss: 0.007\n","[56] loss: 0.007\n","[57] loss: 0.007\n","[58] loss: 0.007\n","[59] loss: 0.007\n","[60] loss: 0.007\n","[61] loss: 0.007\n","[62] loss: 0.007\n","[63] loss: 0.007\n","[64] loss: 0.007\n","[65] loss: 0.007\n","[66] loss: 0.007\n","[67] loss: 0.007\n","[68] loss: 0.007\n","[69] loss: 0.007\n","[70] loss: 0.007\n","[71] loss: 0.007\n","[72] loss: 0.007\n","[73] loss: 0.007\n","[74] loss: 0.007\n","[75] loss: 0.007\n","[76] loss: 0.007\n","[77] loss: 0.007\n","[78] loss: 0.007\n","[79] loss: 0.007\n","[80] loss: 0.007\n","[81] loss: 0.007\n","[82] loss: 0.007\n","[83] loss: 0.007\n","[84] loss: 0.007\n","[85] loss: 0.007\n","[86] loss: 0.007\n","[87] loss: 0.007\n","[88] loss: 0.007\n","[89] loss: 0.007\n","[90] loss: 0.007\n","[91] loss: 0.007\n","[92] loss: 0.007\n","[93] loss: 0.007\n","[94] loss: 0.007\n","[95] loss: 0.007\n","[96] loss: 0.006\n","[97] loss: 0.006\n","[98] loss: 0.006\n","[99] loss: 0.006\n","[100] loss: 0.006\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vZ8QrWTAepS6"},"source":["# Testing student with method 1"]},{"cell_type":"code","metadata":{"id":"RydXmyvIcDJK"},"source":["test_loss = 0\n","correct = 0\n","\n","with torch.no_grad():\n","    for data, target in testloader:\n","        data, target = data.to(device), target.to(device)\n","        output = student_CE(data)\n","        test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","test_loss /= len(testloader.dataset)\n","\n","print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    test_loss, correct, len(testloader.dataset),\n","    100. * correct / len(testloader.dataset)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u8ZTn_hKAQCS"},"source":["# Training student with method 2 (MFPS)"]},{"cell_type":"code","metadata":{"id":"QCNZY5HeAmlo","executionInfo":{"status":"ok","timestamp":1622669493637,"user_tz":-120,"elapsed":196,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}}},"source":["device = \"cuda\"\n","student_MFPS = student()\n","student_MFPS.to(\"cuda\")\n","\n","# bce_with_logits = torch.nn.BCEWithLogitsLoss()\n","learning_rate = 0.001\n","epochs = 100\n","m = nn.Softmax(dim=1)\n","criterion = nn.KLDivLoss()\n","\n","# Set up loss function and optimizer\n","optimizer = optim.SGD(student_MFPS.parameters(), lr=learning_rate, momentum=0.9)"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"YxQhhO6Vofqc","executionInfo":{"status":"error","timestamp":1622669500599,"user_tz":-120,"elapsed":6754,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"35d64d67-8122-48b9-b79d-db7d00243da8"},"source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    total = 0\n","\n","    for image, qs in zip(trainloader, np.array_split(mnistq.get_u_CE(), 480)):\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(student_MFPS.parameters(), lr= learning_rate, momentum=0.9)\n","        \n","        # get the inputs\n","        inputs, targets = image\n","        inputs = inputs.to(\"cuda\")\n","        qs = qs.to(\"cuda\")\n","        \n","        # target = labels.to(\"cuda\").long()\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Set temperature and the weights for losses linear combination\n","        w = 0.7\n","        T = 3\n","\n","        # Student forward + backward + optimize\n","        logits_student = student_MFPS(inputs.float())\n","        loss = criterion(qs, m(logits_student))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(image)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":102,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2611: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["[1] loss: -0.007\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-102-897e0fe6bb20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnistq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_u_CE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Apply the learning rate decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mWELCOME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAuthenticationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'digest sent was rejected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"yZFYVCtNzZLy"},"source":["# Testing student with method 2 (MFPS)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRviYWpAzYwA","executionInfo":{"status":"ok","timestamp":1620239738035,"user_tz":-120,"elapsed":933,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"e460be55-3ad4-42bb-9c95-30d132bed26b"},"source":["test_loss = 0\n","correct = 0\n","\n","with torch.no_grad():\n","    for data, target in testloader:\n","        data, target = data.to(device), target.to(device)\n","        output = student_MFPS(data)\n","        test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","test_loss /= len(testloader.dataset)\n","\n","print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    test_loss, correct, len(testloader.dataset),\n","    100. * correct / len(testloader.dataset)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the network on test images: 33 % (6675 wrong out of 10000)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xokyrdEfAVfZ"},"source":["# Training student with method 2 (MFLS)"]},{"cell_type":"code","metadata":{"id":"yuQUz13nBIP1","executionInfo":{"status":"ok","timestamp":1622670019516,"user_tz":-120,"elapsed":218,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}}},"source":["device = \"cuda\"\n","student_MFLS = student()\n","student_MFLS.to(\"cuda\")\n","\n","# bce_with_logits = torch.nn.BCEWithLogitsLoss()\n","learning_rate = 0.001\n","epochs = 100\n","m = nn.Softmax(dim=1)\n","criterion = nn.KLDivLoss()\n","\n","# Set up loss function and optimizer\n","optimizer = optim.SGD(student_MFLS.parameters(), lr=learning_rate, momentum=0.9)"],"execution_count":106,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFHVhvovpB_l","executionInfo":{"status":"ok","timestamp":1622670379162,"user_tz":-120,"elapsed":358522,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"3e20e8c5-3ef7-42cb-8eb9-6fbad8e61017"},"source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    total = 0\n","\n","    for image, qs in zip(trainloader, np.array_split(mnistq.get_u_MFLS(), 480)):\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(student_MFLS.parameters(), lr= learning_rate, momentum=0.9)\n","        \n","        # get the inputs\n","        inputs, targets = image\n","        inputs = inputs.to(\"cuda\")\n","        qs = qs.to(\"cuda\")\n","        \n","        # target = labels.to(\"cuda\").long()\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Set temperature and the weights for losses linear combination\n","        w = 0.7\n","        T = 8\n","\n","        # Student forward + backward + optimize\n","        logits_student = student_MFLS(inputs.float())\n","        loss = criterion(F.log_softmax(qs/T, dim=1), F.softmax(logits_student/T, dim=1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(image)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":107,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2611: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["[1] loss: 0.021\n","[2] loss: 0.018\n","[3] loss: 0.018\n","[4] loss: 0.018\n","[5] loss: 0.018\n","[6] loss: 0.017\n","[7] loss: 0.017\n","[8] loss: 0.017\n","[9] loss: 0.017\n","[10] loss: 0.017\n","[11] loss: 0.017\n","[12] loss: 0.016\n","[13] loss: 0.016\n","[14] loss: 0.016\n","[15] loss: 0.016\n","[16] loss: 0.016\n","[17] loss: 0.016\n","[18] loss: 0.016\n","[19] loss: 0.016\n","[20] loss: 0.016\n","[21] loss: 0.016\n","[22] loss: 0.016\n","[23] loss: 0.016\n","[24] loss: 0.016\n","[25] loss: 0.016\n","[26] loss: 0.015\n","[27] loss: 0.015\n","[28] loss: 0.015\n","[29] loss: 0.015\n","[30] loss: 0.015\n","[31] loss: 0.015\n","[32] loss: 0.015\n","[33] loss: 0.015\n","[34] loss: 0.015\n","[35] loss: 0.015\n","[36] loss: 0.015\n","[37] loss: 0.015\n","[38] loss: 0.015\n","[39] loss: 0.015\n","[40] loss: 0.015\n","[41] loss: 0.015\n","[42] loss: 0.015\n","[43] loss: 0.015\n","[44] loss: 0.015\n","[45] loss: 0.015\n","[46] loss: 0.015\n","[47] loss: 0.015\n","[48] loss: 0.015\n","[49] loss: 0.015\n","[50] loss: 0.015\n","[51] loss: 0.015\n","[52] loss: 0.015\n","[53] loss: 0.014\n","[54] loss: 0.014\n","[55] loss: 0.014\n","[56] loss: 0.015\n","[57] loss: 0.014\n","[58] loss: 0.014\n","[59] loss: 0.014\n","[60] loss: 0.014\n","[61] loss: 0.014\n","[62] loss: 0.014\n","[63] loss: 0.014\n","[64] loss: 0.014\n","[65] loss: 0.014\n","[66] loss: 0.014\n","[67] loss: 0.014\n","[68] loss: 0.014\n","[69] loss: 0.014\n","[70] loss: 0.014\n","[71] loss: 0.014\n","[72] loss: 0.014\n","[73] loss: 0.014\n","[74] loss: 0.014\n","[75] loss: 0.014\n","[76] loss: 0.014\n","[77] loss: 0.014\n","[78] loss: 0.014\n","[79] loss: 0.014\n","[80] loss: 0.014\n","[81] loss: 0.014\n","[82] loss: 0.014\n","[83] loss: 0.014\n","[84] loss: 0.014\n","[85] loss: 0.014\n","[86] loss: 0.014\n","[87] loss: 0.014\n","[88] loss: 0.014\n","[89] loss: 0.014\n","[90] loss: 0.014\n","[91] loss: 0.014\n","[92] loss: 0.014\n","[93] loss: 0.014\n","[94] loss: 0.014\n","[95] loss: 0.014\n","[96] loss: 0.014\n","[97] loss: 0.014\n","[98] loss: 0.014\n","[99] loss: 0.014\n","[100] loss: 0.014\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hXu1ZRhYBTs7"},"source":["# Testing student with method 2 MFLS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mE-ClvWVBCKB","executionInfo":{"status":"ok","timestamp":1622670386452,"user_tz":-120,"elapsed":543,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"1481c514-0d0e-4b47-edfb-8f2667f3c125"},"source":["test_loss = 0\n","correct = 0\n","\n","with torch.no_grad():\n","    for data, target in testloader:\n","        data, target = data.to(device), target.to(device)\n","        output = student_MFLS(data)\n","        test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","test_loss /= len(testloader.dataset)\n","\n","print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    test_loss, correct, len(testloader.dataset),\n","    100. * correct / len(testloader.dataset)))"],"execution_count":110,"outputs":[{"output_type":"stream","text":["\n","Test set: Average loss: 1.9971, Accuracy: 3189/10000 (32%)\n","\n"],"name":"stdout"}]}]}