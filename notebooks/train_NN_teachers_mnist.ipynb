{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train_teachers_mnist.ipynb","provenance":[],"collapsed_sections":["pJd2ndQTF9Lv","HclMFSKSGDcm","GPljcyaiGMrb","ace4f-rYGQID","u_TMzDioEHI3","qJLfkKzhEabe","XumZKD96EnSt","ERZDqUBHEqXN"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pJd2ndQTF9Lv"},"source":["# Download the MNIST dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEJ2O6YMhqiO","executionInfo":{"status":"ok","timestamp":1622123459269,"user_tz":-120,"elapsed":3435,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"3bbcb930-c919-42c9-8a89-f8cb8739a5b6"},"source":["!wget https://www.dropbox.com/s/h7l845py2d3t6o5/data.zip\n","!unzip data.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-27 13:50:55--  https://www.dropbox.com/s/h7l845py2d3t6o5/data.zip\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/h7l845py2d3t6o5/data.zip [following]\n","--2021-05-27 13:50:55--  https://www.dropbox.com/s/raw/h7l845py2d3t6o5/data.zip\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucfe5fc7f682711769072bead100.dl.dropboxusercontent.com/cd/0/inline/BPQQEVzqzmLUN8rv_FXKaP_OCf1FKImlqpuzzEPPmEHZnccx-M4ytkAkw-_eSSRbY6XqaVJjTSKG8Kw0uTlL8i6bnZpCHc1HowImocNvDq5e1gLOiAwznROKRBFZOqS0iI-z8jiNE3hutholUoBCR88o/file# [following]\n","--2021-05-27 13:50:56--  https://ucfe5fc7f682711769072bead100.dl.dropboxusercontent.com/cd/0/inline/BPQQEVzqzmLUN8rv_FXKaP_OCf1FKImlqpuzzEPPmEHZnccx-M4ytkAkw-_eSSRbY6XqaVJjTSKG8Kw0uTlL8i6bnZpCHc1HowImocNvDq5e1gLOiAwznROKRBFZOqS0iI-z8jiNE3hutholUoBCR88o/file\n","Resolving ucfe5fc7f682711769072bead100.dl.dropboxusercontent.com (ucfe5fc7f682711769072bead100.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n","Connecting to ucfe5fc7f682711769072bead100.dl.dropboxusercontent.com (ucfe5fc7f682711769072bead100.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/BPTI6vGF-K18BHX7bJVxzGn8sGzRq2BnLWW5tPuhNeO5ZrtpmMAZ8IOgTGW8TDJwy6GJ-WwQtSDyRrZReiwkt3xHL2ewai6gWyFP8-KgF3HNjIHdDn-qrLi6HfZuBtPJD-LWbHjeGtXfOmNwJqnjaNgMrV_4j6fU9fdRpaNcROFWhUGMBx03I9h6DM4uooXa9wrRNCvCXeKjz6C-ye6mvoOYrvqMiH6VwFxcnhiysA7kvZIprhazyhCu8aya3QDU9MkXMJhhHKFLIvYBzlZN4WELk0Al41Ec5BQvmrRo_lI6yJgzGE0TpOYavni0f8uDFHljrZkwAtFvGRvNCrApDjXCa0DGdawEl88OqUDj8W6XcUohM5OGg-yISQK1-F4KRzQ/file [following]\n","--2021-05-27 13:50:56--  https://ucfe5fc7f682711769072bead100.dl.dropboxusercontent.com/cd/0/inline2/BPTI6vGF-K18BHX7bJVxzGn8sGzRq2BnLWW5tPuhNeO5ZrtpmMAZ8IOgTGW8TDJwy6GJ-WwQtSDyRrZReiwkt3xHL2ewai6gWyFP8-KgF3HNjIHdDn-qrLi6HfZuBtPJD-LWbHjeGtXfOmNwJqnjaNgMrV_4j6fU9fdRpaNcROFWhUGMBx03I9h6DM4uooXa9wrRNCvCXeKjz6C-ye6mvoOYrvqMiH6VwFxcnhiysA7kvZIprhazyhCu8aya3QDU9MkXMJhhHKFLIvYBzlZN4WELk0Al41Ec5BQvmrRo_lI6yJgzGE0TpOYavni0f8uDFHljrZkwAtFvGRvNCrApDjXCa0DGdawEl88OqUDj8W6XcUohM5OGg-yISQK1-F4KRzQ/file\n","Reusing existing connection to ucfe5fc7f682711769072bead100.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 34602005 (33M) [application/zip]\n","Saving to: ‘data.zip’\n","\n","data.zip            100%[===================>]  33.00M  73.5MB/s    in 0.4s    \n","\n","2021-05-27 13:50:57 (73.5 MB/s) - ‘data.zip’ saved [34602005/34602005]\n","\n","Archive:  data.zip\n","   creating: data/\n","   creating: data/MNIST/\n","   creating: data/MNIST/raw/\n","  inflating: data/MNIST/raw/train-images-idx3-ubyte.gz  \n","  inflating: data/MNIST/raw/train-images-idx3-ubyte  \n","  inflating: data/MNIST/raw/train-labels-idx1-ubyte.gz  \n","  inflating: data/MNIST/raw/train-labels-idx1-ubyte  \n","  inflating: data/MNIST/raw/t10k-images-idx3-ubyte.gz  \n","  inflating: data/MNIST/raw/t10k-images-idx3-ubyte  \n","  inflating: data/MNIST/raw/t10k-labels-idx1-ubyte.gz  \n","  inflating: data/MNIST/raw/t10k-labels-idx1-ubyte  \n","   creating: data/MNIST/processed/\n","  inflating: data/MNIST/processed/training.pt  \n","  inflating: data/MNIST/processed/test.pt  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HclMFSKSGDcm"},"source":["# Create the model and dataset classes"]},{"cell_type":"code","metadata":{"id":"VbUI7yRdFjX1"},"source":["import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import torch.nn as nn\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# Import torchvision functions/classes for MNIST import and data loaders\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# Q = 3*a**3 - b**2\n","\n","class Model(nn.Module):\n","\n","    def __init__(self, n_classes, hidden_size=1200, dropout=0.0, hidden_dropout=0.0):\n","        super(Model, self).__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        self.hidden1 = nn.Linear(784, hidden_size, bias=True)\n","        self.hidden1_dropout = nn.Dropout(hidden_dropout)\n","        self.hidden2 = nn.Linear(hidden_size, hidden_size, bias=True)\n","        self.hidden2_dropout = nn.Dropout(hidden_dropout)\n","        self.hidden3 = nn.Linear(hidden_size, n_classes, bias=True)\n","\n","    def forward(self, x):\n","\n","        x = self.dropout(x)\n","        x = F.relu(self.hidden1(x))\n","        x = self.hidden1_dropout(x)\n","        x = F.relu(self.hidden2(x))\n","        x = self.hidden2_dropout(x)\n","        x = self.hidden3(x)\n","        return x#, F.softmax(x)\n","\n","\n","\n","class MnistDataset(Dataset):\n","    def __init__(self, data, target, transformation=None):\n","        self.images = data\n","        self.targets = target\n","        self.transformation = transforms.Compose([\n","              transforms.RandomAffine(0, (1/14, 1/14)),\n","              transforms.Normalize((0.5,), (0.5,))\n","            ])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","\n","    def __getitem__(self, idx):\n","        return self.images[idx], self.targets[idx]\n","\n","\n","\n","class cnnModel(nn.Module):\n","    def __init__(self):\n","        super(cnnModel, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 128, kernel_size=5)\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n","        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n","        self.fc1 = nn.Linear(3*3*64, 256)\n","        self.fc2 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        #x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(F.max_pool2d(self.conv3(x),2))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = x.view(-1,3*3*64 )\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GPljcyaiGMrb"},"source":["# Train the teacher 0-4"]},{"cell_type":"code","metadata":{"id":"dFyRFOqIMkF6"},"source":["images, targets = torch.load(\"/content/data/MNIST/processed/training.pt\")\n","trainset0to4 = MnistDataset(images, targets)\n","idx = trainset0to4.targets <= 4\n","trainset0to4.images = trainset0to4.images[idx]\n","trainset0to4.targets = trainset0to4.targets[idx]\n","trainloader = torch.utils.data.DataLoader(trainset0to4, batch_size=128, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"AOTVcTu6NODX","executionInfo":{"status":"error","timestamp":1622123924615,"user_tz":-120,"elapsed":13,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"d27c150a-0815-4a6a-9334-26c77089767d"},"source":["# Setup model and move it to the GPU\n","device = 'cuda'\n","# teacher0to4 = Model(n_classes=5, dropout=0.2, hidden_dropout=0.5)\n","teacher0to4 = cnnModel()\n","teacher0to4.to(device)\n","\n","epochs = 20\n","learning_rate = 0.001\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = optim.SGD(teacher0to4.parameters(), lr= learning_rate, momentum=0.9)\n","\n","# Run over 1000 epochs (1 epoch = visited all items in dataset)\n","for epoch in range(epochs):\n","\n","    running_loss = 0.0\n","    total = 0\n","\n","    # for i, data in enumerate(trainloader, 0):\n","    for data in trainloader:\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(teacher0to4.parameters(), \n","                                  lr= learning_rate, momentum=0.9)\n","\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        # inputs = torch.flatten(inputs, start_dim=1).to(device)\n","        inputs = inputs.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = teacher0to4(inputs)\n","        target = labels.to(device).long()\n","        loss = criterion(outputs, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(data)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-aa75b9953fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher0to4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-b4db1b606cd5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;31m#x = F.dropout(x, p=0.5, training=self.training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [128, 1, 5, 5], but got 3-dimensional input of size [128, 28, 28] instead"]}]},{"cell_type":"markdown","metadata":{"id":"ace4f-rYGQID"},"source":["# Train the teacher 5-9"]},{"cell_type":"code","metadata":{"id":"c7J7IsPBTVlR"},"source":["trainset5to9 = MnistDataset(images, targets)\n","idx = trainset5to9.targets >= 5\n","trainset5to9.images = trainset5to9.images[idx]\n","trainset5to9.targets = trainset5to9.targets[idx]\n","trainset5to9.targets = trainset5to9.targets - 5\n","trainloader = torch.utils.data.DataLoader(trainset5to9, batch_size=128, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQs6nUdoTwph","executionInfo":{"status":"ok","timestamp":1620143801836,"user_tz":-120,"elapsed":266182,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"9d77cc8c-dcc4-4b2a-853e-088495442493"},"source":["# Setup model and move it to the GPU\n","device = 'cuda'\n","teacher5to9 = Model(n_classes=5, dropout=0.2, hidden_dropout=0.5)\n","teacher5to9.to(device)\n","\n","epochs = 300\n","learning_rate = 0.001\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = optim.SGD(teacher5to9.parameters(), lr=learning_rate, momentum=0.9)\n","\n","# Run over 1000 epochs (1 epoch = visited all items in dataset)\n","for epoch in range(epochs):\n","\n","    running_loss = 0.0\n","    total = 0\n","\n","    # for i, data in enumerate(trainloader, 0):\n","    for data in trainloader:\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(teacher5to9.parameters(), lr= learning_rate, momentum=0.9)\n","\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = teacher5to9(inputs.float())\n","        target = labels.to(device).long()\n","        loss = criterion(outputs, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(data)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1] loss: 1.258\n","[2] loss: 0.142\n","[3] loss: 0.117\n","[4] loss: 0.097\n","[5] loss: 0.089\n","[6] loss: 0.082\n","[7] loss: 0.079\n","[8] loss: 0.071\n","[9] loss: 0.069\n","[10] loss: 0.062\n","[11] loss: 0.063\n","[12] loss: 0.058\n","[13] loss: 0.056\n","[14] loss: 0.054\n","[15] loss: 0.055\n","[16] loss: 0.052\n","[17] loss: 0.047\n","[18] loss: 0.046\n","[19] loss: 0.046\n","[20] loss: 0.044\n","[21] loss: 0.043\n","[22] loss: 0.044\n","[23] loss: 0.042\n","[24] loss: 0.039\n","[25] loss: 0.038\n","[26] loss: 0.040\n","[27] loss: 0.039\n","[28] loss: 0.039\n","[29] loss: 0.036\n","[30] loss: 0.035\n","[31] loss: 0.035\n","[32] loss: 0.032\n","[33] loss: 0.036\n","[34] loss: 0.034\n","[35] loss: 0.031\n","[36] loss: 0.032\n","[37] loss: 0.032\n","[38] loss: 0.030\n","[39] loss: 0.031\n","[40] loss: 0.030\n","[41] loss: 0.030\n","[42] loss: 0.029\n","[43] loss: 0.029\n","[44] loss: 0.028\n","[45] loss: 0.025\n","[46] loss: 0.027\n","[47] loss: 0.029\n","[48] loss: 0.026\n","[49] loss: 0.026\n","[50] loss: 0.028\n","[51] loss: 0.025\n","[52] loss: 0.026\n","[53] loss: 0.026\n","[54] loss: 0.026\n","[55] loss: 0.025\n","[56] loss: 0.026\n","[57] loss: 0.024\n","[58] loss: 0.025\n","[59] loss: 0.024\n","[60] loss: 0.024\n","[61] loss: 0.024\n","[62] loss: 0.024\n","[63] loss: 0.023\n","[64] loss: 0.021\n","[65] loss: 0.021\n","[66] loss: 0.021\n","[67] loss: 0.021\n","[68] loss: 0.021\n","[69] loss: 0.021\n","[70] loss: 0.020\n","[71] loss: 0.020\n","[72] loss: 0.021\n","[73] loss: 0.021\n","[74] loss: 0.020\n","[75] loss: 0.020\n","[76] loss: 0.019\n","[77] loss: 0.020\n","[78] loss: 0.020\n","[79] loss: 0.019\n","[80] loss: 0.019\n","[81] loss: 0.019\n","[82] loss: 0.020\n","[83] loss: 0.019\n","[84] loss: 0.020\n","[85] loss: 0.020\n","[86] loss: 0.017\n","[87] loss: 0.018\n","[88] loss: 0.018\n","[89] loss: 0.019\n","[90] loss: 0.019\n","[91] loss: 0.018\n","[92] loss: 0.017\n","[93] loss: 0.018\n","[94] loss: 0.017\n","[95] loss: 0.018\n","[96] loss: 0.018\n","[97] loss: 0.018\n","[98] loss: 0.017\n","[99] loss: 0.017\n","[100] loss: 0.017\n","[101] loss: 0.015\n","[102] loss: 0.017\n","[103] loss: 0.015\n","[104] loss: 0.015\n","[105] loss: 0.016\n","[106] loss: 0.015\n","[107] loss: 0.015\n","[108] loss: 0.016\n","[109] loss: 0.016\n","[110] loss: 0.016\n","[111] loss: 0.016\n","[112] loss: 0.017\n","[113] loss: 0.016\n","[114] loss: 0.016\n","[115] loss: 0.014\n","[116] loss: 0.016\n","[117] loss: 0.016\n","[118] loss: 0.015\n","[119] loss: 0.015\n","[120] loss: 0.015\n","[121] loss: 0.016\n","[122] loss: 0.014\n","[123] loss: 0.016\n","[124] loss: 0.016\n","[125] loss: 0.016\n","[126] loss: 0.015\n","[127] loss: 0.015\n","[128] loss: 0.016\n","[129] loss: 0.015\n","[130] loss: 0.015\n","[131] loss: 0.016\n","[132] loss: 0.015\n","[133] loss: 0.016\n","[134] loss: 0.017\n","[135] loss: 0.016\n","[136] loss: 0.014\n","[137] loss: 0.015\n","[138] loss: 0.015\n","[139] loss: 0.015\n","[140] loss: 0.017\n","[141] loss: 0.016\n","[142] loss: 0.015\n","[143] loss: 0.015\n","[144] loss: 0.015\n","[145] loss: 0.016\n","[146] loss: 0.016\n","[147] loss: 0.015\n","[148] loss: 0.016\n","[149] loss: 0.015\n","[150] loss: 0.016\n","[151] loss: 0.015\n","[152] loss: 0.015\n","[153] loss: 0.015\n","[154] loss: 0.015\n","[155] loss: 0.015\n","[156] loss: 0.015\n","[157] loss: 0.015\n","[158] loss: 0.015\n","[159] loss: 0.016\n","[160] loss: 0.015\n","[161] loss: 0.017\n","[162] loss: 0.016\n","[163] loss: 0.014\n","[164] loss: 0.016\n","[165] loss: 0.016\n","[166] loss: 0.016\n","[167] loss: 0.016\n","[168] loss: 0.015\n","[169] loss: 0.016\n","[170] loss: 0.016\n","[171] loss: 0.015\n","[172] loss: 0.016\n","[173] loss: 0.015\n","[174] loss: 0.017\n","[175] loss: 0.016\n","[176] loss: 0.016\n","[177] loss: 0.015\n","[178] loss: 0.015\n","[179] loss: 0.016\n","[180] loss: 0.015\n","[181] loss: 0.016\n","[182] loss: 0.015\n","[183] loss: 0.016\n","[184] loss: 0.016\n","[185] loss: 0.014\n","[186] loss: 0.015\n","[187] loss: 0.017\n","[188] loss: 0.015\n","[189] loss: 0.015\n","[190] loss: 0.016\n","[191] loss: 0.015\n","[192] loss: 0.014\n","[193] loss: 0.017\n","[194] loss: 0.017\n","[195] loss: 0.014\n","[196] loss: 0.016\n","[197] loss: 0.016\n","[198] loss: 0.016\n","[199] loss: 0.018\n","[200] loss: 0.014\n","[201] loss: 0.015\n","[202] loss: 0.016\n","[203] loss: 0.015\n","[204] loss: 0.014\n","[205] loss: 0.016\n","[206] loss: 0.016\n","[207] loss: 0.015\n","[208] loss: 0.015\n","[209] loss: 0.016\n","[210] loss: 0.015\n","[211] loss: 0.016\n","[212] loss: 0.016\n","[213] loss: 0.015\n","[214] loss: 0.016\n","[215] loss: 0.016\n","[216] loss: 0.016\n","[217] loss: 0.015\n","[218] loss: 0.016\n","[219] loss: 0.016\n","[220] loss: 0.016\n","[221] loss: 0.015\n","[222] loss: 0.016\n","[223] loss: 0.016\n","[224] loss: 0.015\n","[225] loss: 0.016\n","[226] loss: 0.016\n","[227] loss: 0.015\n","[228] loss: 0.017\n","[229] loss: 0.015\n","[230] loss: 0.016\n","[231] loss: 0.014\n","[232] loss: 0.016\n","[233] loss: 0.016\n","[234] loss: 0.015\n","[235] loss: 0.015\n","[236] loss: 0.016\n","[237] loss: 0.016\n","[238] loss: 0.015\n","[239] loss: 0.014\n","[240] loss: 0.016\n","[241] loss: 0.015\n","[242] loss: 0.016\n","[243] loss: 0.016\n","[244] loss: 0.017\n","[245] loss: 0.014\n","[246] loss: 0.016\n","[247] loss: 0.016\n","[248] loss: 0.016\n","[249] loss: 0.014\n","[250] loss: 0.015\n","[251] loss: 0.017\n","[252] loss: 0.015\n","[253] loss: 0.016\n","[254] loss: 0.016\n","[255] loss: 0.016\n","[256] loss: 0.015\n","[257] loss: 0.016\n","[258] loss: 0.015\n","[259] loss: 0.016\n","[260] loss: 0.016\n","[261] loss: 0.016\n","[262] loss: 0.016\n","[263] loss: 0.015\n","[264] loss: 0.015\n","[265] loss: 0.016\n","[266] loss: 0.015\n","[267] loss: 0.015\n","[268] loss: 0.015\n","[269] loss: 0.015\n","[270] loss: 0.016\n","[271] loss: 0.015\n","[272] loss: 0.015\n","[273] loss: 0.015\n","[274] loss: 0.014\n","[275] loss: 0.015\n","[276] loss: 0.017\n","[277] loss: 0.016\n","[278] loss: 0.015\n","[279] loss: 0.016\n","[280] loss: 0.017\n","[281] loss: 0.016\n","[282] loss: 0.015\n","[283] loss: 0.016\n","[284] loss: 0.017\n","[285] loss: 0.016\n","[286] loss: 0.015\n","[287] loss: 0.014\n","[288] loss: 0.016\n","[289] loss: 0.016\n","[290] loss: 0.014\n","[291] loss: 0.014\n","[292] loss: 0.015\n","[293] loss: 0.015\n","[294] loss: 0.016\n","[295] loss: 0.015\n","[296] loss: 0.016\n","[297] loss: 0.015\n","[298] loss: 0.015\n","[299] loss: 0.016\n","[300] loss: 0.015\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u_TMzDioEHI3"},"source":["# Testing the teacher 0-4"]},{"cell_type":"code","metadata":{"id":"kYQ23nuQVJH6"},"source":["images, targets = torch.load(\"/content/data/MNIST/processed/test.pt\")\n","testset0to4 = MnistDataset(images, targets)\n","idx = testset0to4.targets <= 4\n","testset0to4.images = testset0to4.images[idx]\n","testset0to4.targets = testset0to4.targets[idx]\n","testloader = torch.utils.data.DataLoader(testset0to4, batch_size=128, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3ejtpz_WmdV","executionInfo":{"status":"ok","timestamp":1620144215107,"user_tz":-120,"elapsed":792,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"88d77b67-d6ad-43a8-9a1c-bf81b2110097"},"source":["# Define support function used to convert label to one-hot encoded tensor\n","def convert_labels(labels):\n","    target = torch.zeros([len(labels), 10], dtype=torch.float32)\n","    for i, l in enumerate(labels):\n","      target[i][l] = 1.0\n","    return target\n","\n","\n","# Run model on test set and determine accuracy\n","correct = 0\n","total = 0\n","\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(device)\n","        target = convert_labels(labels).to(device)\n","        outputs = teacher0to4(inputs.float())\n","        _, predicted = torch.max(outputs.data, 1)\n","        _, target = torch.max(target.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","        # for i, val in enumerate(predicted):\n","        #   wrong[target[i]][val] += 1\n","\n","# Output model accuracy to user\n","print('Accuracy of the network on test images: %d %% (%d wrong out of %d)' % (\n","    100 * correct / total, total - correct, total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the network on test images: 99 % (48 wrong out of 5139)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qJLfkKzhEabe"},"source":["# Testing the teacher 5-9"]},{"cell_type":"code","metadata":{"id":"ES4mRrjCXXQy"},"source":["images, targets = torch.load(\"/content/data/MNIST/processed/test.pt\")\n","testset5to9 = MnistDataset(images, targets)\n","idx = testset5to9.targets >= 5\n","testset5to9.images = testset5to9.images[idx]\n","testset5to9.targets = testset5to9.targets[idx]\n","testset5to9.targets = testset5to9.targets - 5\n","testloader = torch.utils.data.DataLoader(testset5to9, batch_size=128, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99Q3UCzgX6in","executionInfo":{"status":"ok","timestamp":1620144325916,"user_tz":-120,"elapsed":1072,"user":{"displayName":"Aitor Lucas","photoUrl":"","userId":"07298394126490224130"}},"outputId":"629c83a0-904f-4ef0-f1a7-ca449da228ba"},"source":["# Run model on test set and determine accuracy\n","correct = 0\n","total = 0\n","\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(device)\n","        target = convert_labels(labels).to(device)\n","        outputs = teacher5to9(inputs.float())\n","        _, predicted = torch.max(outputs.data, 1)\n","        _, target = torch.max(target.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","        # for i, val in enumerate(predicted):\n","        #   wrong[target[i]][val] += 1\n","\n","# Output model accuracy to user\n","print('Accuracy of the network on test images: %d %% (%d wrong out of %d)' % (\n","    100 * correct / total, total - correct, total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the network on test images: 97 % (103 wrong out of 4861)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XumZKD96EnSt"},"source":["# Save teacher models"]},{"cell_type":"code","metadata":{"id":"_dOzFPddYClS"},"source":["torch.save(teacher0to4, \"teacher0to4.pt\")\n","torch.save(teacher5to9, \"teacher5to9.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ERZDqUBHEqXN"},"source":["# Train student"]},{"cell_type":"code","metadata":{"id":"fZG-Iz-PaBOb"},"source":["def student_loss(outputs, labels, teacher_outputs, alpha, temperature):\n","\n","    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),\n","                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\\n","              F.cross_entropy(outputs, labels) * (1. - alpha)\n","\n","    return KD_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jR5Cqd6tfjWY"},"source":["images, targets = torch.load(\"/content/data/MNIST/processed/training.pt\")\n","trainset0to6 = MnistDataset(images, targets)\n","idx = trainset0to6.targets <= 6\n","trainset0to6.images = trainset0to6.images[idx]\n","trainset0to6.targets = trainset0to6.targets[idx]\n","trainloader = torch.utils.data.DataLoader(trainset0to6, batch_size=128, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"o53HDN9RYuE7"},"source":["# Setup model and move it to the GPU\n","device = 'cuda'\n","student = Model(n_classes=7, hidden_size=800, dropout=0.2, hidden_dropout=0.5)\n","student.to(device)\n","\n","learning_rate = 0.001\n","\n","# Set up loss function and optimizer\n","optimizer = optim.SGD(student.parameters(), lr=0.001, momentum=0.9)\n","\n","# Run over 1000 epochs (1 epoch = visited all items in dataset)\n","for epoch in range(500):\n","    running_loss = 0.0\n","    total = 0\n","\n","    for data in trainloader:\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(student.parameters(), lr= learning_rate, momentum=0.9)\n","        \n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(device)\n","        target = labels.to(device).long()\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Set temperature and the weights for losses linear combination\n","        w = 0.7\n","        T = 20\n","\n","        # Compute soft labels using deep teacher model previously trained\n","        outputs_teacher = teacher0to6(inputs.float())\n","\n","        # Student forward + backward + optimize\n","        outputs_stud = student(inputs.float())\n","        \n","        loss = student_loss(outputs_stud, target, outputs_teacher, w, T)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(data)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nZDeP8gkTQsC"},"source":["images, targets = torch.load(\"/content/data/MNIST/processed/test.pt\")\n","images_train, targets_train = torch.load(\"/content/data/MNIST/processed/training.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"WCXiMmS7Tonk","executionInfo":{"status":"ok","timestamp":1617708974293,"user_tz":-120,"elapsed":739,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"53005f63-fbe6-4448-e258-6c77d4914630"},"source":["plt.imshow(images[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f9345943710>"]},"metadata":{"tags":[]},"execution_count":30},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANiklEQVR4nO3df4wc9XnH8c8n/kV8QGtDcF3j4ISQqE4aSHWBRNDKESUFImSiJBRLtVyJ5lALElRRW0QVBalVSlEIok0aySluHESgaQBhJTSNa6W1UKljg4yxgdaEmsau8QFOaxPAP/DTP24cHXD7vWNndmft5/2SVrs7z87Oo/F9PLMzO/t1RAjA8e9tbTcAoD8IO5AEYQeSIOxAEoQdSGJ6Pxc207PiBA31c5FAKq/qZzoYBzxRrVbYbV8s6XZJ0yT9bUTcXHr9CRrSeb6wziIBFGyIdR1rXe/G254m6auSLpG0WNIy24u7fT8AvVXnM/u5kp6OiGci4qCkeyQtbaYtAE2rE/YFkn4y7vnOatrr2B6xvcn2pkM6UGNxAOro+dH4iFgZEcMRMTxDs3q9OAAd1An7LkkLxz0/vZoGYADVCftGSWfZfpftmZKulLSmmbYANK3rU28Rcdj2tZL+SWOn3lZFxLbGOgPQqFrn2SPiQUkPNtQLgB7i67JAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJGoN2Wx7h6T9kl6TdDgihptoCkDzaoW98rGIeKGB9wHQQ+zGA0nUDXtI+oHtR2yPTPQC2yO2N9nedEgHai4OQLfq7sZfEBG7bJ8maa3tpyJi/fgXRMRKSSsl6WTPjZrLA9ClWlv2iNhV3Y9Kul/SuU00BaB5XYfd9pDtk44+lvRxSVubagxAs+rsxs+TdL/to+/zrYj4fiNdAWhc12GPiGcknd1gLwB6iFNvQBKEHUiCsANJEHYgCcIOJNHEhTApvPjZj3asvXP508V5nxqdV6wfPDCjWF9wd7k+e+dLHWtHNj9RnBd5sGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4zz5Ff/xH3+pY+9TQT8szn1lz4UvK5R2HX+5Yu/35j9Vc+LHrR6NndKwN3foLxXmnr3uk6XZax5YdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JwRP8GaTnZc+M8X9i35TXpZ58+r2PthQ+W/8+c82R5Hf/0V1ysz/zg/xbrt3zgvo61i97+SnHe7718YrH+idmdr5Wv65U4WKxvODBUrC854VDXy37P964u1t87srHr927ThlinfbF3wj8otuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATXs0/R0Hc2FGr13vvkerPrr39pScfan5+/qLzsfy3/5v0tS97TRUdTM/2VI8X60Jbdxfop6+8t1n91Zuff25+9o/xb/MejSbfstlfZHrW9ddy0ubbX2t5e3c/pbZsA6prKbvw3JF38hmk3SFoXEWdJWlc9BzDAJg17RKyXtPcNk5dKWl09Xi3p8ob7AtCwbj+zz4uIox+onpPUcTAz2yOSRiTpBM3ucnEA6qp9ND7GrqTpeKVHRKyMiOGIGJ6hWXUXB6BL3YZ9j+35klTdjzbXEoBe6DbsayStqB6vkPRAM+0A6JVJP7Pbvltjv1x+qu2dkr4g6WZJ37Z9laRnJV3RyyZRdvi5PR1rQ/d2rknSa5O899B3Xuyio2bs+b2PFuvvn1n+8/3S3vd1rC36u2eK8x4uVo9Nk4Y9IpZ1KB2bv0IBJMXXZYEkCDuQBGEHkiDsQBKEHUiCS1zRmulnLCzWv3LjV4r1GZ5WrP/D7b/ZsXbK7oeL8x6P2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKcZ0drnvrDBcX6h2eVh7LedrA8HPXcJ15+yz0dz9iyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASnGdHTx34xIc71h799G2TzF0eQej3r7uuWH/7v/1okvfPhS07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBeXb01H9f0nl7cqLL59GX/ddFxfrs7z9WrEexms+kW3bbq2yP2t46btpNtnfZ3lzdLu1tmwDqmspu/DckXTzB9Nsi4pzq9mCzbQFo2qRhj4j1kvb2oRcAPVTnAN21trdUu/lzOr3I9ojtTbY3HdKBGosDUEe3Yf+apDMlnSNpt6RbO70wIlZGxHBEDM+Y5MIGAL3TVdgjYk9EvBYRRyR9XdK5zbYFoGldhd32/HFPPylpa6fXAhgMk55nt323pCWSTrW9U9IXJC2xfY7GTmXukHR1D3vEAHvbSScV68t//aGOtX1HXi3OO/rFdxfrsw5sLNbxepOGPSKWTTD5jh70AqCH+LoskARhB5Ig7EAShB1IgrADSXCJK2rZftP7i/Xvnvo3HWtLt3+qOO+sBzm11iS27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOfZUfR/v/ORYn3Lb/9Vsf7jw4c61l76y9OL887S7mIdbw1bdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgvPsyU1f8MvF+vWf//tifZbLf0JXPra8Y+0d/8j16v3Elh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuA8+3HO08v/xGd/d2ex/pkTXyzW79p/WrE+7/OdtydHinOiaZNu2W0vtP1D20/Y3mb7umr6XNtrbW+v7uf0vl0A3ZrKbvxhSZ+LiMWSPiLpGtuLJd0gaV1EnCVpXfUcwICaNOwRsTsiHq0e75f0pKQFkpZKWl29bLWky3vVJID63tJndtuLJH1I0gZJ8yLi6I+EPSdpXod5RiSNSNIJmt1tnwBqmvLReNsnSrpX0vURsW98LSJCUkw0X0SsjIjhiBieoVm1mgXQvSmF3fYMjQX9roi4r5q8x/b8qj5f0mhvWgTQhEl3421b0h2SnoyIL48rrZG0QtLN1f0DPekQ9Zz9vmL5z067s9bbf/WLnynWf/Gxh2u9P5ozlc/s50taLulx25uraTdqLOTftn2VpGclXdGbFgE0YdKwR8RDktyhfGGz7QDoFb4uCyRB2IEkCDuQBGEHkiDsQBJc4nocmLb4vR1rI/fU+/rD4lXXFOuL7vz3Wu+P/mHLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ79OPDUH3T+Yd/LZu/rWJuK0//lYPkFMeEPFGEAsWUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4z34MePWyc4v1dZfdWqgy5BbGsGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSSmMj77QknflDRPUkhaGRG3275J0mclPV+99MaIeLBXjWb2P+dPK9bfOb37c+l37T+tWJ+xr3w9O1ezHzum8qWaw5I+FxGP2j5J0iO211a12yLiS71rD0BTpjI++25Ju6vH+20/KWlBrxsD0Ky39Jnd9iJJH5K0oZp0re0ttlfZnvC3kWyP2N5ke9MhHajVLIDuTTnstk+UdK+k6yNin6SvSTpT0jka2/JP+AXtiFgZEcMRMTxDsxpoGUA3phR22zM0FvS7IuI+SYqIPRHxWkQckfR1SeWrNQC0atKw27akOyQ9GRFfHjd9/riXfVLS1ubbA9CUqRyNP1/SckmP295cTbtR0jLb52js7MsOSVf3pEPU8hcvLi7WH/6tRcV67H68wW7QpqkcjX9IkicocU4dOIbwDTogCcIOJEHYgSQIO5AEYQeSIOxAEo4+Drl7sufGeb6wb8sDstkQ67Qv9k50qpwtO5AFYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dfz7Lafl/TsuEmnSnqhbw28NYPa26D2JdFbt5rs7YyIeMdEhb6G/U0LtzdFxHBrDRQMam+D2pdEb93qV2/sxgNJEHYgibbDvrLl5ZcMam+D2pdEb93qS2+tfmYH0D9tb9kB9AlhB5JoJey2L7b9H7aftn1DGz10YnuH7cdtb7a9qeVeVtketb113LS5ttfa3l7dTzjGXku93WR7V7XuNtu+tKXeFtr+oe0nbG+zfV01vdV1V+irL+ut75/ZbU+T9J+SLpK0U9JGScsi4om+NtKB7R2ShiOi9S9g2P4NSS9J+mZEfKCadoukvRFxc/Uf5ZyI+JMB6e0mSS+1PYx3NVrR/PHDjEu6XNLvqsV1V+jrCvVhvbWxZT9X0tMR8UxEHJR0j6SlLfQx8CJivaS9b5i8VNLq6vFqjf2x9F2H3gZCROyOiEerx/slHR1mvNV1V+irL9oI+wJJPxn3fKcGa7z3kPQD24/YHmm7mQnMi4jd1ePnJM1rs5kJTDqMdz+9YZjxgVl33Qx/XhcH6N7sgoj4NUmXSLqm2l0dSDH2GWyQzp1OaRjvfplgmPGfa3PddTv8eV1thH2XpIXjnp9eTRsIEbGruh+VdL8GbyjqPUdH0K3uR1vu5+cGaRjviYYZ1wCsuzaHP28j7BslnWX7XbZnSrpS0poW+ngT20PVgRPZHpL0cQ3eUNRrJK2oHq+Q9ECLvbzOoAzj3WmYcbW87lof/jwi+n6TdKnGjsj/WNKfttFDh77eLemx6rat7d4k3a2x3bpDGju2cZWkUyStk7Rd0j9LmjtAvd0p6XFJWzQWrPkt9XaBxnbRt0jaXN0ubXvdFfrqy3rj67JAEhygA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/h9BCfQTVPflJQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"9tn4qE1HcD9J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617708398409,"user_tz":-120,"elapsed":11092,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"cd2de4ae-088b-415d-82fd-d02d3cd56041"},"source":["teacher1 = torch.load(\"teacher0to6.pt\")\n","teacher1.to(\"cuda\")\n","teacher2 = torch.load(\"teacher3to9.pt\")\n","teacher2.to(\"cuda\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (hidden1): Linear(in_features=784, out_features=1200, bias=True)\n","  (hidden1_dropout): Dropout(p=0.5, inplace=False)\n","  (hidden2): Linear(in_features=1200, out_features=1200, bias=True)\n","  (hidden2_dropout): Dropout(p=0.5, inplace=False)\n","  (hidden3): Linear(in_features=1200, out_features=7, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"gzCXoxWCTiil"},"source":["img1 = images[2].to(\"cuda\") #1\n","img2 = images[4].to(\"cuda\") #4\n","img3 = images[0].to(\"cuda\") #7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2gFXa1_SNiJ","executionInfo":{"status":"ok","timestamp":1617708551742,"user_tz":-120,"elapsed":603,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"d6dead57-0abb-4d11-e56d-2725b62c20e5"},"source":["teacher2(img2.reshape(1, 784).float())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-11.6992,  17.8440, -11.1168,  -0.3323,   4.5431,  -1.7922,   8.2899]],\n","       device='cuda:0', grad_fn=<AddmmBackward>)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"Nc-bVhaAUHJW"},"source":["z1_1 = teacher1(img1.reshape(1, 784).float()) #logits teacher1 per num 1\n","z1_2 = teacher2(img1.reshape(1, 784).float()) #logits teacher2 per num 1\n","\n","z2_1 = teacher1(img2.reshape(1, 784).float()) #logits teacher1 per num 4\n","z2_2 = teacher2(img2.reshape(1, 784).float()) #logits teacher2 per num 4\n","\n","z3_1 = teacher1(img3.reshape(1, 784).float()) #logits teacher1 per num 7\n","z3_2 = teacher2(img3.reshape(1, 784).float()) #logits teacher2 per num 7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3JAdSB8KVYGo"},"source":["m = nn.Softmax(dim=1)\n","\n","probs_t1 = m(z3_1)\n","probs_t2 = m(z3_2)\n","\n","probs_t1 = probs_t1.cpu().data.numpy()\n","probs_t2 = probs_t2.cpu().data.numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLQRSLo8NQCs","executionInfo":{"status":"ok","timestamp":1617708563718,"user_tz":-120,"elapsed":694,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"d7f2c5da-c7b7-45e2-c302-6df1d85c95c1"},"source":["dict_probs_t1 = {}\n","dict_probs_t2 = {}\n","\n","for idx in range(7):\n","    dict_probs_t1[idx] = probs_t1[0][idx]\n","\n","for idx in range(3, 10):\n","    dict_probs_t2[idx] = probs_t2[0][idx - 3]\n","\n","print(dict_probs_t1)\n","print(dict_probs_t2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{0: 0.0101718595, 1: 2.157596e-05, 2: 0.53603435, 3: 0.4334892, 4: 0.0017076073, 5: 0.01857305, 6: 2.345939e-06}\n","{3: 2.776103e-07, 4: 4.216657e-11, 5: 9.1008195e-10, 6: 2.3212262e-19, 7: 0.9999994, 8: 9.484371e-10, 9: 3.7950514e-07}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shvxg3VRR1aX","executionInfo":{"status":"ok","timestamp":1617708570879,"user_tz":-120,"elapsed":553,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"311a9343-ee06-41a4-bf40-beadb6f0007d"},"source":["def grad_j(dict_probs_t1, dict_probs_t2, u):\n","    grad_j = np.random.rand(10)\n","    for i,u_i in enumerate(u):\n","        dui = 0\n","        if i in dict_probs_t1.keys():\n","            dui = dui - dict_probs_t1[i]\n","            e = np.exp(u_i)/np.sum(np.exp(list(dict_probs_t1.values())))\n","            dui = dui + np.sum(np.array(list(dict_probs_t1.values()))*e)\n","        if i in dict_probs_t2.keys():\n","            dui = dui - dict_probs_t2[i]\n","            e = np.exp(u_i)/np.sum(np.exp(list(dict_probs_t2.values())))\n","            dui = dui + np.sum(np.array(list(dict_probs_t2.values()))*e)\n","        grad_j[i] = dui\n","    return grad_j\n","    \n","u = np.random.rand(10)\n","for it in range(100):\n","    u = u - 0.1 * grad_j(dict_probs_t1, dict_probs_t2, u)\n","\n","def compute_q(dict)\n","\n","print(u)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[-0.72046277 -0.79381421  1.47618259  0.60033151 -1.20343489 -1.09552558\n"," -1.21452235  2.16519081 -0.76612846 -0.76612568]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6nn94oY9INS","executionInfo":{"status":"ok","timestamp":1617719007184,"user_tz":-120,"elapsed":1083,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"0f181f30-277c-4e1e-85e5-69b28dc3abc8"},"source":["def grad_j(dict_probs_t1, dict_probs_t2, u):\n","    grad_j = np.random.rand(10)\n","    for i,u_i in enumerate(u):\n","        dui = 0\n","        if i in dict_probs_t1.keys():\n","            dui = dui - dict_probs_t1[i]\n","            e = np.exp(u_i)/np.sum(np.exp(list(dict_probs_t1.values())))\n","            dui = dui + np.sum(np.array(list(dict_probs_t1.values()))*e)\n","        if i in dict_probs_t2.keys():\n","            dui = dui - dict_probs_t2[i]\n","            e = np.exp(u_i)/np.sum(np.exp(list(dict_probs_t2.values())))\n","            dui = dui + np.sum(np.array(list(dict_probs_t2.values()))*e)\n","        grad_j[i] = dui\n","    return grad_j\n","\n","\n","iters = 100\n","m = nn.Softmax(dim=1)\n","m2 = nn.Softmax()\n","q2 = torch.rand([images_train.shape[0],10])\n","\n","for i in range(images_train.shape[0])[:10]:\n","    # Obtain image\n","    img = images_train[i].to(\"cuda\")\n","    \n","    # Obtain logits from teacher\n","    z1 = teacher1(img.reshape(1, 784).float())\n","    z2 = teacher2(img.reshape(1, 784).float())\n","    \n","    # compute softmax to obtain p_i\n","    probs_t1 = m(z1).cpu().data.numpy()[0] \n","    probs_t2 = m(z2).cpu().data.numpy()[0]\n","    print(probs_t1)\n","    print(probs_t2)\n","\n","    dict_probs_t1 = {idx:probs_t1[idx] for idx in range(7)}\n","    dict_probs_t2 = {idx:probs_t2[idx-3] for idx in range(3, 10)}\n","\n","    # compute gradient descent\n","    u = np.random.rand(10)\n","    for it in range(iters):\n","        u = u - 0.1 * grad_j(dict_probs_t1, dict_probs_t2, u)\n","    \n","    # compute softmax to obtain q\n","    q2[i] = m2(torch.from_numpy(u))\n","    if i%100==0: print(f'Computing q of image: {i}')\n","    print(q2[i])\n","    print()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[8.7859308e-07 4.1704817e-07 2.3125999e-06 4.8301388e-02 1.6423806e-07\n"," 9.5168871e-01 6.0112498e-06]\n","[7.9523915e-01 5.4650513e-16 2.0391746e-01 3.5566090e-17 1.2459070e-08\n"," 2.6144001e-08 8.4336201e-04]\n","Computing q of image: 0\n","tensor([0.0389, 0.0389, 0.0389, 0.3028, 0.0251, 0.4149, 0.0251, 0.0384, 0.0384,\n","        0.0387])\n","\n","[1.0000000e+00 4.4699798e-21 1.4657111e-13 9.1459322e-17 8.8119887e-15\n"," 3.1025978e-16 3.0977543e-09]\n","[0.10898796 0.02977746 0.0897084  0.5497459  0.02682933 0.08194578\n"," 0.11300517]\n","tensor([0.5565, 0.0297, 0.0297, 0.0359, 0.0228, 0.0323, 0.1477, 0.0348, 0.0501,\n","        0.0606])\n","\n","[9.5134549e-09 8.5265361e-13 2.3735411e-06 1.9420778e-08 9.9999762e-01\n"," 2.7389408e-12 9.3391780e-11]\n","[4.1900779e-07 9.8747987e-01 2.6866273e-06 2.3296420e-07 4.6015231e-04\n"," 2.9171244e-04 1.1764901e-02]\n","tensor([0.0375, 0.0375, 0.0375, 0.0244, 0.6984, 0.0244, 0.0244, 0.0376, 0.0375,\n","        0.0408])\n","\n","[8.1788194e-14 1.0000000e+00 2.5015480e-12 1.8737793e-13 8.9008037e-12\n"," 7.3944872e-14 2.8208330e-13]\n","[9.1772490e-06 1.1698269e-02 1.1275812e-07 8.5697275e-07 9.8778278e-01\n"," 4.1043435e-04 9.8308185e-05]\n","tensor([0.0228, 0.4273, 0.0228, 0.0148, 0.0160, 0.0148, 0.0148, 0.4211, 0.0228,\n","        0.0228])\n","\n","[3.0166951e-09 2.4698700e-03 1.4315602e-08 1.7577857e-03 9.9575990e-01\n"," 1.2410875e-05 6.8248864e-09]\n","[2.2703952e-04 1.8200181e-02 2.1386868e-04 4.3616176e-08 9.6893154e-06\n"," 4.1020787e-04 9.8093903e-01]\n","tensor([0.0287, 0.0293, 0.0287, 0.0189, 0.2727, 0.0187, 0.0187, 0.0287, 0.0288,\n","        0.5268])\n","\n","[2.3255556e-14 2.2740291e-07 9.9996054e-01 3.9254504e-05 2.2230950e-09\n"," 1.6202761e-10 1.4524462e-12]\n","[2.4090379e-02 1.6113354e-03 3.5857123e-03 8.2966080e-04 4.1804449e-03\n"," 9.5743513e-01 8.2673691e-03]\n","tensor([0.0231, 0.0231, 0.4324, 0.0175, 0.0151, 0.0153, 0.0150, 0.0237, 0.4106,\n","        0.0244])\n","\n","[6.9092954e-25 1.0000000e+00 4.5290977e-19 5.8033072e-20 2.2056208e-13\n"," 9.8253770e-24 2.0398050e-19]\n","[1.7694703e-03 8.3551378e-05 5.6444430e-03 2.5719052e-04 5.0635409e-04\n"," 9.9095470e-01 7.8431639e-04]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["tensor([0.0228, 0.4267, 0.0228, 0.0150, 0.0148, 0.0153, 0.0148, 0.0228, 0.4221,\n","        0.0229])\n","\n","[6.3758308e-26 6.1798101e-18 3.9375237e-15 1.0000000e+00 1.4642666e-24\n"," 2.6012228e-16 1.8982915e-35]\n","[9.9996924e-01 1.4776839e-15 1.4766550e-12 3.3818189e-23 8.3293088e-09\n"," 3.9637993e-07 3.0426860e-05]\n","tensor([0.0374, 0.0374, 0.0374, 0.7023, 0.0244, 0.0244, 0.0244, 0.0374, 0.0374,\n","        0.0375])\n","\n","[2.0531465e-19 1.0000000e+00 6.5970235e-17 1.6741420e-15 2.9234698e-11\n"," 4.7663080e-17 3.4294825e-17]\n","[0.01409361 0.20498638 0.55737245 0.00415134 0.0334498  0.1435456\n"," 0.04240084]\n","tensor([0.0294, 0.5512, 0.0294, 0.0205, 0.0558, 0.1485, 0.0192, 0.0361, 0.0716,\n","        0.0384])\n","\n","[2.4268029e-28 2.7643161e-28 1.1559910e-16 1.4410366e-25 1.0000000e+00\n"," 1.1951029e-26 7.4900868e-30]\n","[4.3751496e-15 1.0000000e+00 4.7351896e-14 2.1987448e-13 1.0115954e-10\n"," 1.3392108e-14 4.4576058e-11]\n","tensor([0.0374, 0.0374, 0.0374, 0.0244, 0.7023, 0.0244, 0.0244, 0.0374, 0.0374,\n","        0.0374])\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nw01ua4hjjrC","executionInfo":{"status":"ok","timestamp":1617718896246,"user_tz":-120,"elapsed":512,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"283b553e-96b8-4330-910b-cb4c7d6ec1ec"},"source":["for i in range(10):\n","    print()\n","    print(q2[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0.0376, 0.0376, 0.0402, 0.0270, 0.0245, 0.6956, 0.0247, 0.0377, 0.0377,\n","        0.0377])\n","tensor([0.5448, 0.0291, 0.0291, 0.0187, 0.0294, 0.0202, 0.1971, 0.0286, 0.0422,\n","        0.0610])\n","tensor([0.0375, 0.0375, 0.0375, 0.0244, 0.7004, 0.0244, 0.0244, 0.0375, 0.0375,\n","        0.0391])\n","tensor([0.0255, 0.4780, 0.0255, 0.0508, 0.0239, 0.0168, 0.0192, 0.3081, 0.0254,\n","        0.0267])\n","tensor([0.0287, 0.0287, 0.0287, 0.0289, 0.2481, 0.0194, 0.0187, 0.0289, 0.0289,\n","        0.5413])\n","tensor([0.0247, 0.0247, 0.4634, 0.0429, 0.0160, 0.0162, 0.0159, 0.3365, 0.0328,\n","        0.0269])\n","tensor([0.0292, 0.5472, 0.0292, 0.1307, 0.0431, 0.0190, 0.0186, 0.0698, 0.0529,\n","        0.0605])\n","tensor([0.0374, 0.0374, 0.0374, 0.7023, 0.0244, 0.0244, 0.0244, 0.0374, 0.0374,\n","        0.0374])\n","tensor([0.0279, 0.5233, 0.0279, 0.0192, 0.0669, 0.0302, 0.0202, 0.1421, 0.0525,\n","        0.0898])\n","tensor([0.0374, 0.0374, 0.0374, 0.0244, 0.7023, 0.0244, 0.0244, 0.0374, 0.0374,\n","        0.0374])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"SnRPDItFLr_y","executionInfo":{"status":"ok","timestamp":1617715779583,"user_tz":-120,"elapsed":622,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"ea807aa0-b160-4fd5-9c14-147b94444200"},"source":["plt.imshow(images_train[1]);"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"quPjMLJZX9U5","executionInfo":{"status":"ok","timestamp":1617715783194,"user_tz":-120,"elapsed":537,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"9c9b2327-b54b-460e-dc24-709fd3f3c2b5"},"source":["for i,p in enumerate(q[1]):\n","    print(f'{i}: {p}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0: 0.4780184030532837\n","1: 0.025491097941994667\n","2: 0.025491097941994667\n","3: 0.01655544899404049\n","4: 0.01968778483569622\n","5: 0.022822504863142967\n","6: 0.0297218170017004\n","7: 0.04491875320672989\n","8: 0.038451991975307465\n","9: 0.29884108901023865\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"jmvFQA94X-Pg","executionInfo":{"status":"ok","timestamp":1617715808415,"user_tz":-120,"elapsed":677,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"9cf6ba23-6020-438e-ebd9-e96761bb462d"},"source":["plt.imshow(images_train[0]);"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KoMT4m05YEXJ","executionInfo":{"status":"ok","timestamp":1617715816754,"user_tz":-120,"elapsed":580,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"e546d137-4b47-46c1-ff29-15440f81dac3"},"source":["for i,p in enumerate(q[0]):\n","    print(f'{i}: {p}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0: 0.03744512051343918\n","1: 0.03744512051343918\n","2: 0.03744512051343918\n","3: 0.024399463087320328\n","4: 0.02435402385890484\n","5: 0.7022225260734558\n","6: 0.02435402385890484\n","7: 0.03744395449757576\n","8: 0.03744395449757576\n","9: 0.03744671121239662\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"tMnx0TkXYGbM","executionInfo":{"status":"ok","timestamp":1617715838066,"user_tz":-120,"elapsed":1038,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"bc89e4a3-a212-428c-c501-4fec5698474e"},"source":["plt.imshow(images_train[4]);"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fz5UcdF9YLgq","executionInfo":{"status":"ok","timestamp":1617716052702,"user_tz":-120,"elapsed":638,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"86a0bd72-bcd9-440a-fb43-5bcb4b15564d"},"source":["for i,p in enumerate(q[4]):\n","    print(f'{i}: {p}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0: 0.028607642278075218\n","1: 0.028629299253225327\n","2: 0.029097916558384895\n","3: 0.020536988973617554\n","4: 0.2602550983428955\n","5: 0.01986829936504364\n","6: 0.018598005175590515\n","7: 0.028652815148234367\n","8: 0.028647642582654953\n","9: 0.5371063351631165\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydxc7Cxqbe4J","executionInfo":{"status":"ok","timestamp":1617716714766,"user_tz":-120,"elapsed":666,"user":{"displayName":"Noel Rabella Gras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgRhAqfRjlQNX80VNxk5yyBu2-P0eqe6p8YASVJ=s64","userId":"12084925594555696479"}},"outputId":"af9423c0-c32b-424a-c94a-71fb67e80d30"},"source":["q"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0374, 0.0374, 0.0374,  ..., 0.0374, 0.0374, 0.0374],\n","        [0.4780, 0.0255, 0.0255,  ..., 0.0449, 0.0385, 0.2988],\n","        [0.0376, 0.0376, 0.0376,  ..., 0.0393, 0.0375, 0.0428],\n","        ...,\n","        [0.0374, 0.0374, 0.0374,  ..., 0.0374, 0.0374, 0.0374],\n","        [0.0375, 0.0375, 0.0375,  ..., 0.0375, 0.0375, 0.0375],\n","        [0.2370, 0.0256, 0.0269,  ..., 0.0263, 0.4938, 0.0263]])"]},"metadata":{"tags":[]},"execution_count":121}]},{"cell_type":"code","metadata":{"id":"AA2ETEl2aqHh"},"source":["def student_loss(outputs, labels, teacher_outputs, alpha, temperature):\n","\n","    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),\n","                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\\n","              F.cross_entropy(outputs, labels) * (1. - alpha)\n","\n","    return KD_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8E4pPzCZAAW"},"source":["# Setup model and move it to the GPU\n","device = 'cuda'\n","student = Model(n_classes=7, hidden_size=800, dropout=0.2, hidden_dropout=0.5)\n","student.to(device)\n","\n","learning_rate = 0.001\n","\n","# Set up loss function and optimizer\n","optimizer = optim.SGD(student.parameters(), lr=0.001, momentum=0.9)\n","\n","# Run over 1000 epochs (1 epoch = visited all items in dataset)\n","for epoch in range(500):\n","    running_loss = 0.0\n","    total = 0\n","\n","    for data in trainloader:\n","        # Apply the learning rate decay\n","        if(epoch % 100 == 0 and epoch != 0):\n","            learning_rate = learning_rate * 0.5\n","            optimizer = optim.SGD(student.parameters(), lr= learning_rate, momentum=0.9)\n","        \n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs = torch.flatten(inputs, start_dim=1).to(device)\n","        target = labels.to(device).long()\n","        \n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Set temperature and the weights for losses linear combination\n","        w = 0.7\n","        T = 20\n","\n","        # Compute soft labels using deep teacher model previously trained\n","        outputs_teacher = teacher0to6(inputs.float())\n","\n","        # Student forward + backward + optimize\n","        outputs_stud = student(inputs.float())\n","        \n","        loss = student_loss(outputs_stud, target, outputs_teacher, w, T)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total += len(data)\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    # print every epoch\n","    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n","\n","print('Finished Training')"],"execution_count":null,"outputs":[]}]}